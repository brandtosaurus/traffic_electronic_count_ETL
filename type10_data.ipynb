{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calcs\n",
    "import main\n",
    "import config\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import uuid\n",
    "from io import StringIO\n",
    "import csv\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "src = r\"S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\"\n",
    "test1 = r\"S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0006-20211231.RSV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE10_DATA_COLUMN_NAMES = ['id', 'site_id', 'header_id', \"year\", 'number_of_fields_associated_with_the_basic_vehicle_data', 'data_source_code', 'edit_code', 'departure_date', 'departure_time', 'assigned_lane_number', 'physical_lane_number', 'forward_reverse_code', 'vehicle_category', 'vehicle_class_code_primary_scheme', 'vehicle_class_code_secondary_scheme', 'vehicle_speed', 'vehicle_length', 'site_occupancy_time_in_milliseconds', 'chassis_height_code', 'vehicle_following_code', 'vehicle_tag_code', 'trailer_count', 'axle_count', 'bumper_to_1st_axle_spacing', 'tyre_type', 'sub_data_type_code_vx', 'vehicle_registration_number', 'number_of_images', 'image_name_1', 'image_name_2', 'image_name_3', 'sub_data_type_code_sx', 'number_of_axles_spacings_counted', 'axle_spacing_1_between_individual_axles_cm', 'axle_spacing_2_between_individual_axles_cm', 'axle_spacing_3_between_individual_axles_cm', 'axle_spacing_4_between_individual_axles_cm', 'axle_spacing_5_between_individual_axles_cm', 'axle_spacing_6_between_individual_axles_cm', 'axle_spacing_7_between_individual_axles_cm', 'axle_spacing_8_between_individual_axles_cm'\n",
    "]\n",
    "\n",
    "TYPE10_HEADER_COLUMN_NAMES = ['header_id', 'data_description', 'vehicle_classification_scheme_primary', 'vehicle_classification_scheme_secondary', 'maximum_gap_milliseconds', 'maximum_differential_speed'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfiles(path: str):\n",
    "    print(\"COLLECTING FILES......\")\n",
    "    src = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if (\n",
    "                name.endswith(\".RSA\")\n",
    "                or name.endswith(\".rsa\")\n",
    "                or name.endswith(\".rsv\")\n",
    "                or name.endswith(\".RSV\")\n",
    "            ):\n",
    "                p = os.path.join(root, name)\n",
    "                src.append(p)\n",
    "    src = list(set(src))\n",
    "    return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(file: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(file, header=None, sep=\"\\n\")\n",
    "    df = df[0].str.split(\"\\s+|,\\s+|,\", expand=True)\n",
    "    df = pd.DataFrame(df)\n",
    "    return df\n",
    "\n",
    "def push_to_db(df, table, subset) -> None:\n",
    "    try:\n",
    "        df.to_sql(\n",
    "            table,\n",
    "            con=config.ENGINE,\n",
    "            schema=\"trafc\",\n",
    "            if_exists=\"append\",\n",
    "            index=False,\n",
    "            method=psql_insert_copy,\n",
    "        )\n",
    "    except Exception:\n",
    "        df = df.drop_duplicates(subset=subset)\n",
    "        df.to_sql(\n",
    "            table,\n",
    "            con=config.ENGINE,\n",
    "            schema=\"trafc\",\n",
    "            if_exists=\"append\",\n",
    "            index=False,\n",
    "            method=psql_insert_copy,\n",
    "        )\n",
    "\n",
    "\n",
    "def psql_insert_copy(table, conn, keys, data_iter):\n",
    "    \"\"\"\n",
    "    Execute SQL statement inserting data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    table : pandas.io.sql.SQLTable\n",
    "    conn : sqlalchemy.engine.Engine or sqlalchemy.engine.Connection\n",
    "    keys : list of str\n",
    "        Column names\n",
    "    data_iter : Iterable that iterates the values to be inserted\n",
    "    \"\"\"\n",
    "    # gets a DBAPI connection that can provide a cursor\n",
    "    dbapi_conn = conn.connection\n",
    "    with dbapi_conn.cursor() as cur:\n",
    "        s_buf = StringIO()\n",
    "        writer = csv.writer(s_buf)\n",
    "        writer.writerows(data_iter)\n",
    "        s_buf.seek(0)\n",
    "\n",
    "        columns = \", \".join('\"{}\"'.format(k) for k in keys)\n",
    "        if table.schema:\n",
    "            table_name = \"{}.{}\".format(table.schema, table.name)\n",
    "        else:\n",
    "            table_name = table.name\n",
    "\n",
    "        sql = \"COPY {} ({}) FROM STDIN WITH CSV\".format(table_name, columns)\n",
    "        cur.copy_expert(sql=sql, file=s_buf)\n",
    "\n",
    "def join(header: pd.DataFrame, data: pd.DataFrame) -> pd.DataFrame:\n",
    "    if data.empty:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        q = \"\"\"\n",
    "\t\tSELECT header.header_id, header.station_name, data.*\n",
    "\t\tFROM header\n",
    "\t\tLEFT JOIN data ON data.start_datetime WHERE data.start_datetime >= header.start_datetime AND data.end_datetime <= header.end_datetime;\n",
    "\t\t\"\"\"\n",
    "        q2 = \"\"\"UPDATE data set header_id = (SELECT header_id from header WHERE data.start_datetime >= header.start_datetime AND data.counttime_end <= header.enddate)\"\"\"\n",
    "        pysqldf = lambda q: sqldf(q, globals())\n",
    "        df = sqldf(q, locals())\n",
    "        df = pd.DataFrame(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def data_join(data: pd.DataFrame, header: pd.DataFrame) -> pd.DataFrame:\n",
    "    if data is None:\n",
    "        pass\n",
    "    elif data.empty:\n",
    "        pass\n",
    "    else:\n",
    "        data = pd.DataFrame(data)\n",
    "        data = join(header, data)\n",
    "    return data\n",
    "\n",
    "def get_direction(lane_number, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        filt = df[1] == lane_number\n",
    "        df = df.where(filt)\n",
    "        df = df[2].dropna()\n",
    "        df = int(df)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLLECTING FILES......\n"
     ]
    }
   ],
   "source": [
    "files = getfiles(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "donelist = ['S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0127-20220131.RSV',\n",
    "'S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0013-20220228.RSV',\n",
    "'S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0131-20211231.RSV',\n",
    "'S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0123-20220228.RSV',\n",
    "'S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0009-20220228.RSV',\n",
    "'S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0073-20220131.RSV',\n",
    "'S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0108-20220131.RSV',\n",
    "'S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0123-20220131.RSV',\n",
    "'S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0123-20211231.RSV',\n",
    "'S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0337-20220131.RSV',\n",
    "'S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0313-20220131.RSV',\n",
    "'S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0323-20211231.RSV',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = to_df(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head(df) -> pd.DataFrame:\n",
    "    dfh = pd.DataFrame(\n",
    "        df.loc[\n",
    "            (df[0].isin([\"H0\", \"S0\", \"I0\", \"S1\", \"D0\", \"D1\", \"D3\", \"L0\", \"L1\"]))\n",
    "            | (\n",
    "                (df[0].isin([\"21\", \"70\", \"30\", \"13\", \"60\"]))\n",
    "                & (~df[1].isin([\"0\", \"1\", \"2\", \"3\", \"4\"]))\n",
    "            )\n",
    "            | (\n",
    "                (df[0].isin([\"10\"]))\n",
    "                & (df[1].isin([\"1\", \"8\", \"5\", \"01\", \"08\", \"05\"]))\n",
    "            )\n",
    "        ]\n",
    "    ).dropna(axis=1, how=\"all\")\n",
    "    dfh[\"index\"] = dfh.index\n",
    "    breaks = dfh[\"index\"].diff() != 1\n",
    "    groups = breaks.cumsum()\n",
    "    dfh[\"newindex\"] = groups\n",
    "    dfh = dfh.set_index(\"newindex\")\n",
    "    dfh = dfh.drop(columns=[\"index\"])\n",
    "    return dfh\n",
    "\n",
    "def headers(dfh: pd.DataFrame) -> pd.DataFrame:\n",
    "    if not dfh.empty:\n",
    "        headers = pd.DataFrame()\n",
    "        headers[\"site_id\"] = dfh.loc[dfh[0] == \"S0\", 1].astype(str)\n",
    "        if not dfh.loc[dfh[0] == \"S1\", 1:].empty:\n",
    "            headers[\"station_name\"] = (\n",
    "                dfh.loc[dfh[0] == \"S1\", 1:]\n",
    "                .dropna(axis=1)\n",
    "                .apply(\" \".join, axis=1)\n",
    "                .astype(str)\n",
    "            )\n",
    "        else:\n",
    "            headers[\"station_name\"] = (\n",
    "                dfh.loc[dfh[0] == \"S0\", 2:]\n",
    "                .dropna(axis=1)\n",
    "                .apply(\" \".join, axis=1)\n",
    "                .astype(str)\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            headers[\"y\"] = dfh.loc[dfh[0] == \"S0\", 5].astype(float)\n",
    "            headers[\"x\"] = dfh.loc[dfh[0] == \"S0\", 6].astype(float)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        headers[\"number_of_lanes\"] = dfh.loc[dfh[0] == \"L0\", 2].astype(int)\n",
    "\n",
    "        try:\n",
    "            headers[\"speedbin1\"] = dfh.loc[dfh[0] == \"21\", 4].astype(int)\n",
    "            headers[\"speedbin2\"] = dfh.loc[dfh[0] == \"21\", 5].astype(int)\n",
    "            headers[\"speedbin3\"] = dfh.loc[dfh[0] == \"21\", 6].astype(int)\n",
    "            headers[\"speedbin4\"] = dfh.loc[dfh[0] == \"21\", 7].astype(int)\n",
    "            headers[\"speedbin5\"] = dfh.loc[dfh[0] == \"21\", 8].astype(int)\n",
    "            headers[\"speedbin6\"] = dfh.loc[dfh[0] == \"21\", 9].astype(int)\n",
    "            headers[\"speedbin7\"] = dfh.loc[dfh[0] == \"21\", 10].astype(int)\n",
    "            headers[\"speedbin8\"] = dfh.loc[dfh[0] == \"21\", 11].astype(int)\n",
    "            headers[\"speedbin9\"] = dfh.loc[dfh[0] == \"21\", 12].astype(int)\n",
    "            headers[\"type_21_count_interval_minutes\"] = dfh.loc[\n",
    "                dfh[0] == \"21\", 1\n",
    "            ].astype(int)\n",
    "            headers[\"type_21_programmable_rear_to_rear_headway_bin\"] = dfh.loc[\n",
    "                dfh[0] == \"21\", 3\n",
    "            ].astype(int)\n",
    "            headers[\"type_21_program_id\"] = \"2\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            headers[\"type_10_vehicle_classification_scheme_primary\"] = dfh.loc[\n",
    "                dfh[0] == \"10\", 1\n",
    "            ].astype(int)\n",
    "            headers[\"type_10_vehicle_classification_scheme_secondary\"] = dfh.loc[\n",
    "                dfh[0] == \"10\", 2\n",
    "            ].astype(int)\n",
    "            headers[\"type_10_maximum_gap_milliseconds\"] = dfh.loc[\n",
    "                dfh[0] == \"10\", 3\n",
    "            ].astype(int)\n",
    "            headers[\"type_10_maximum_differential_speed\"] = dfh.loc[\n",
    "                dfh[0] == \"10\", 4\n",
    "            ].astype(int)\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            headers[\"type_30_summary_interval_minutes\"] = dfh.loc[\n",
    "                dfh[0] == \"30\", 2\n",
    "            ].astype(int)\n",
    "            headers[\"type_30_vehicle_classification_scheme\"] = dfh.loc[\n",
    "                dfh[0] == \"30\", 3\n",
    "            ].astype(int)\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            headers[\"type_70_summary_interval_minutes\"] = dfh.loc[\n",
    "                dfh[0] == \"70\", 1\n",
    "            ].astype(int)\n",
    "            headers[\"type_70_vehicle_classification_scheme\"] = dfh.loc[\n",
    "                dfh[0] == \"70\", 2\n",
    "            ].astype(int)\n",
    "            headers[\"type_70_maximum_gap_milliseconds\"] = dfh.loc[\n",
    "                dfh[0] == \"70\", 3\n",
    "            ].astype(int)\n",
    "            headers[\"type_70_maximum_differential_speed\"] = dfh.loc[\n",
    "                dfh[0] == \"70\", 4\n",
    "            ].astype(int)\n",
    "            headers[\"type_70_error_bin_code\"] = dfh.loc[dfh[0] == \"70\", 5].astype(\n",
    "                int\n",
    "            )\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if not dfh.loc[dfh[0] == \"D3\", 1].empty:\n",
    "            headers[\"start_datetime\"] = dfh.loc[dfh[0] == \"D3\", 1].astype(str)\n",
    "            headers[\"start_time\"] = dfh.loc[dfh[0] == \"D3\", 2].astype(str)\n",
    "            headers[\"end_datetime\"] = dfh.loc[dfh[0] == \"D3\", 3].astype(str)\n",
    "            headers[\"end_time\"] = dfh.loc[dfh[0] == \"D3\", 4].astype(str)\n",
    "        else:\n",
    "            headers[\"start_datetime\"] = dfh.loc[dfh[0] == \"D1\", 1].astype(str)\n",
    "            headers[\"start_time\"] = dfh.loc[dfh[0] == \"D1\", 2].astype(str)\n",
    "            headers[\"end_datetime\"] = dfh.loc[dfh[0] == \"D1\", 3].astype(str)\n",
    "            headers[\"end_time\"] = dfh.loc[dfh[0] == \"D1\", 4].astype(str)\n",
    "\n",
    "        # headers[\"end_datetime\"] = headers.apply(\n",
    "        #     lambda x: pd.to_datetime(\n",
    "        #         x[\"end_datetime\"] + x[\"end_time\"], format=\"%y%m%d%H%M%S\"\n",
    "        #     )\n",
    "        #     if (\n",
    "        #         x[\"end_time\"] != \"240000\"\n",
    "        #         and len(x[\"end_datetime\"]) == 6\n",
    "        #         and len(x[\"end_time\"]) == 6\n",
    "        #     )\n",
    "        #     else (\n",
    "        #         pd.to_datetime(\n",
    "        #             x[\"end_datetime\"] + x[\"end_time\"], format=\"%y%m%d%H%M%S%f\"\n",
    "        #         )\n",
    "        #         if (\n",
    "        #             x[\"end_time\"] != \"24000000\"\n",
    "        #             and len(x[\"end_datetime\"]) == 6\n",
    "        #             and len(x[\"end_time\"]) == 8\n",
    "        #         )\n",
    "        #         else (\n",
    "        #             pd.to_datetime(\n",
    "        #                 x[\"end_datetime\"] + x[\"end_time\"], format=\"%Y%m%d%H%M%S\"\n",
    "        #             )\n",
    "        #             if (\n",
    "        #                 x[\"end_time\"] != \"240000\"\n",
    "        #                 and len(x[\"end_datetime\"]) == 8\n",
    "        #                 and len(x[\"end_time\"]) == 6\n",
    "        #             )\n",
    "        #             else (\n",
    "        #                 pd.to_datetime(\n",
    "        #                     x[\"end_datetime\"] + x[\"end_time\"],\n",
    "        #                     format=\"%Y%m%d%H%M%S%f\",\n",
    "                        # )\n",
    "                        # if (\n",
    "                        #     x[\"end_time\"] != \"24000000\"\n",
    "                        #     and len(x[\"end_datetime\"]) == 8\n",
    "                        #     and len(x[\"end_time\"]) == 8\n",
    "                        # )\n",
    "                        # else (\n",
    "                        #     pd.to_datetime(x[\"end_datetime\"], format=\"%y%m%d\")\n",
    "                        #     + timedelta(days=1)\n",
    "                        #     if (\n",
    "                        #         x[\"end_time\"] == \"240000\"\n",
    "                        #         and len(x[\"end_datetime\"]) == 6\n",
    "                            #     and len(x[\"end_time\"]) == 6\n",
    "                            # )\n",
    "                            # else (\n",
    "                            #     pd.to_datetime(x[\"end_datetime\"], format=\"%y%m%d\")\n",
    "                            #     + timedelta(days=1)\n",
    "                            #     if (\n",
    "                            #         x[\"end_time\"] == \"24000000\"\n",
    "                            #         and len(x[\"end_datetime\"]) == 6\n",
    "                            #         and len(x[\"end_time\"]) == 8\n",
    "                            #     )\n",
    "                            #     else (\n",
    "                            #         pd.to_datetime(\n",
    "                            #             x[\"end_datetime\"], format=\"%Y%m%d\"\n",
    "                            #         )\n",
    "                            #         + timedelta(days=1)\n",
    "                            #         if (\n",
    "                            #             x[\"end_time\"] == \"240000\"\n",
    "                                #         and len(x[\"end_datetime\"]) == 8\n",
    "                                #         and len(x[\"end_time\"]) == 6\n",
    "                                #     )\n",
    "                                #     else (\n",
    "                                #         pd.to_datetime(\n",
    "                                #             x[\"end_datetime\"], format=\"%Y%m%d\"\n",
    "                                #         )\n",
    "                                #         + timedelta(days=1)\n",
    "                                #         if (\n",
    "                                #             x[\"end_time\"] == \"24000000\"\n",
    "                                #             and len(x[\"end_datetime\"]) == 8\n",
    "                                #             and len(x[\"end_time\"]) == 8\n",
    "                                #         )\n",
    "                                #         else pd.to_datetime(\n",
    "                                #             x[\"end_datetime\"] + x[\"end_time\"]\n",
    "                                #         )\n",
    "                                #     )\n",
    "                                # )\n",
    "        #                     )\n",
    "        #                 )\n",
    "        #             )\n",
    "        #         )\n",
    "        #     ),\n",
    "        #     axis=1,\n",
    "        # )\n",
    "\n",
    "        # headers[\"start_datetime\"] = headers.apply(\n",
    "        #     lambda x: pd.to_datetime(\n",
    "        #         x[\"start_datetime\"] + x[\"start_time\"], format=\"%y%m%d%H%M%S\"\n",
    "        #     )\n",
    "        #     if (\n",
    "        #         x[\"start_time\"] != \"240000\"\n",
    "        #         and len(x[\"start_datetime\"]) == 6\n",
    "        #         and len(x[\"start_time\"]) == 6\n",
    "        #     )\n",
    "        #     else (\n",
    "        #         pd.to_datetime(\n",
    "        #             x[\"start_datetime\"] + x[\"start_time\"], format=\"%y%m%d%H%M%S%f\"\n",
    "        #         )\n",
    "        #         if (\n",
    "        #             x[\"start_time\"] != \"24000000\"\n",
    "        #             and len(x[\"start_datetime\"]) == 6\n",
    "        #             and len(x[\"start_time\"]) == 8\n",
    "        #         )\n",
    "        #         else (\n",
    "        #             pd.to_datetime(\n",
    "        #                 x[\"start_datetime\"] + x[\"start_time\"], format=\"%Y%m%d%H%M%S\"\n",
    "        #             )\n",
    "        #             if (\n",
    "        #                 x[\"start_time\"] != \"240000\"\n",
    "        #                 and len(x[\"start_datetime\"]) == 8\n",
    "                    #     and len(x[\"start_time\"]) == 6\n",
    "                    # )\n",
    "                    # else (\n",
    "                    #     pd.to_datetime(\n",
    "                    #         x[\"start_datetime\"] + x[\"start_time\"],\n",
    "                    #         format=\"%Y%m%d%H%M%S%f\",\n",
    "                    #     )\n",
    "                    #     if (\n",
    "                    #         x[\"start_time\"] != \"24000000\"\n",
    "                    #         and len(x[\"start_datetime\"]) == 8\n",
    "                    #         and len(x[\"start_time\"]) == 8\n",
    "                    #     )\n",
    "                    #     else (\n",
    "                    #         pd.to_datetime(x[\"start_datetime\"], format=\"%y%m%d\")\n",
    "                    #         + timedelta(days=1)\n",
    "                    #         if (\n",
    "                    #             x[\"start_time\"] == \"240000\"\n",
    "                    #             and len(x[\"start_datetime\"]) == 6\n",
    "                    #             and len(x[\"start_time\"]) == 6\n",
    "                    #         )\n",
    "                            # else (\n",
    "                            #     pd.to_datetime(x[\"start_datetime\"], format=\"%y%m%d\")\n",
    "                            #     + timedelta(days=1)\n",
    "                            #     if (\n",
    "                            #         x[\"start_time\"] == \"24000000\"\n",
    "                            #         and len(x[\"start_datetime\"]) == 6\n",
    "                            #         and len(x[\"start_time\"]) == 8\n",
    "                            #     )\n",
    "                            #     else (\n",
    "                            #         pd.to_datetime(\n",
    "                            #             x[\"start_datetime\"], format=\"%Y%m%d\"\n",
    "                            #         )\n",
    "                            #         + timedelta(days=1)\n",
    "                            #         if (\n",
    "                            #             x[\"start_time\"] == \"240000\"\n",
    "                            #             and len(x[\"start_datetime\"]) == 8\n",
    "                            #             and len(x[\"start_time\"]) == 6\n",
    "                            #         )\n",
    "        #                             else (\n",
    "        #                                 pd.to_datetime(\n",
    "        #                                     x[\"start_datetime\"], format=\"%Y%m%d\"\n",
    "        #                                 )\n",
    "        #                                 + timedelta(days=1)\n",
    "        #                                 if (\n",
    "        #                                     x[\"start_time\"] == \"24000000\"\n",
    "        #                                     and len(x[\"start_datetime\"]) == 8\n",
    "        #                                     and len(x[\"start_time\"]) == 8\n",
    "        #                                 )\n",
    "        #                                 else pd.to_datetime(\n",
    "        #                                     x[\"start_datetime\"] + x[\"start_time\"]\n",
    "        #                                 )\n",
    "        #                             )\n",
    "        #                         )\n",
    "        #                     )\n",
    "        #                 )\n",
    "        #             )\n",
    "        #         )\n",
    "        #     ),\n",
    "        #     axis=1,\n",
    "        # )\n",
    "\n",
    "        # headers = headers.drop([\"start_time\"], axis=1)\n",
    "        # headers = headers.drop([\"end_time\"], axis=1)\n",
    "\n",
    "        # headers[\"start_datetime\"] = pd.to_datetime(headers[\"start_datetime\"])\n",
    "        # headers[\"end_datetime\"] = pd.to_datetime(headers[\"end_datetime\"])\n",
    "        headers[\"site_id\"] = headers[\"site_id\"].astype(str)\n",
    "\n",
    "        try:\n",
    "            headers[\"instrumentation_description\"] = (\n",
    "                dfh.loc[dfh[0] == \"I0\", 1:]\n",
    "                .dropna(axis=1)\n",
    "                .apply(\" \".join, axis=1)\n",
    "                .astype(str)\n",
    "            )\n",
    "        except Exception:\n",
    "            headers[\"instrumentation_description\"] = None\n",
    "\n",
    "        try:\n",
    "            headers[\"type_30_summary_interval_minutes\"] = headers[\n",
    "                \"type_21_count_interval_minutes\"\n",
    "            ]\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            headers[\"type_70_summary_interval_minutes\"] = headers[\n",
    "                \"type_21_count_interval_minutes\"\n",
    "            ]\n",
    "            headers[\"type_70_vehicle_classification_scheme\"] = headers[\n",
    "                \"type_21_count_interval_minutes\"\n",
    "            ]\n",
    "            headers[\"type_70_vehicle_classification_scheme\"] = headers[\n",
    "                \"type_21_count_interval_minutes\"\n",
    "            ]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        headers = headers.fillna(method=\"ffill\")\n",
    "        headers = headers.fillna(method=\"bfill\")\n",
    "\n",
    "        headers = headers.drop_duplicates(ignore_index=True)\n",
    "\n",
    "        headers[\"header_id\"] = \"\"\n",
    "        headers[\"header_id\"] = headers[\"header_id\"].apply(\n",
    "            lambda x: str(uuid.uuid4())\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    return headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtype10(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    data = df.loc[(df[0] == \"10\") & (df[1].isin([\"15\", \"17\", \"19\"]))].dropna(\n",
    "        axis=1, how=\"all\"\n",
    "    )\n",
    "    dfh2 = pd.DataFrame(df.loc[(df[0].isin([\"S0\", \"L1\"]))]).dropna(\n",
    "        axis=1, how=\"all\"\n",
    "    )\n",
    "    if data.empty:\n",
    "        print(\"data empty\")\n",
    "        print(data)\n",
    "    else:\n",
    "        ddf = data.iloc[:, 4:]\n",
    "        ddf = pd.DataFrame(ddf).dropna(axis=1, how=\"all\")\n",
    "        if (data[1].isin(['15','17']).all()\n",
    "            and len(ddf.columns) == 11\n",
    "        ):\n",
    "            ddf.columns = [\n",
    "                \"departure_date\",\n",
    "                \"departure_time\",\n",
    "                \"assigned_lane_number\",\n",
    "                \"physical_lane_number\",\n",
    "                \"forward_reverse_code\",\n",
    "                \"vehicle_category\",\n",
    "                \"vehicle_class_code_primary_scheme\",\n",
    "                \"vehicle_class_code_secondary_scheme\",\n",
    "                \"vehicle_speed\",\n",
    "                \"vehicle_length\",\n",
    "                \"site_occupancy_time_in_milliseconds\",\n",
    "                \"chassis_height_code\",\n",
    "                \"vehicle_following_code\",\n",
    "            ]\n",
    "            ddf = pd.concat(\n",
    "                [\n",
    "                    ddf,\n",
    "                    pd.DataFrame(\n",
    "                        columns=[\n",
    "                            \"vehicle_tag_code\",\n",
    "                            \"trailer_count\",\n",
    "                            \"axle_count\",\n",
    "                            \"bumper_to_1st_axle_spacing\",\n",
    "                            \"sub_data_type_code_sx\",\n",
    "                            \"number_of_axles_spacings_counted\",\n",
    "                        ]\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        elif (data[1].isin(['15','17']).all()\n",
    "            and len(ddf.columns) == 13\n",
    "        ):\n",
    "            ddf.columns = [\n",
    "                \"departure_date\",\n",
    "                \"departure_time\",\n",
    "                \"assigned_lane_number\",\n",
    "                \"physical_lane_number\",\n",
    "                \"forward_reverse_code\",\n",
    "                \"vehicle_category\",\n",
    "                \"vehicle_class_code_primary_scheme\",\n",
    "                \"vehicle_class_code_secondary_scheme\",\n",
    "                \"vehicle_speed\",\n",
    "                \"vehicle_length\",\n",
    "                \"site_occupancy_time_in_milliseconds\",\n",
    "                \"chassis_height_code\",\n",
    "                \"vehicle_following_code\",\n",
    "            ]\n",
    "            ddf = pd.concat(\n",
    "                [\n",
    "                    ddf,\n",
    "                    pd.DataFrame(\n",
    "                        columns=[\n",
    "                            \"vehicle_tag_code\",\n",
    "                            \"trailer_count\",\n",
    "                            \"axle_count\",\n",
    "                            \"bumper_to_1st_axle_spacing\",\n",
    "                            \"sub_data_type_code_sx\",\n",
    "                            \"number_of_axles_spacings_counted\",\n",
    "                        ]\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        elif (data[1].isin(['15','17']).all()\n",
    "            and len(ddf.columns) == 15\n",
    "        ):\n",
    "            ddf.columns = [\n",
    "                \"departure_date\",\n",
    "                \"departure_time\",\n",
    "                \"assigned_lane_number\",\n",
    "                \"physical_lane_number\",\n",
    "                \"forward_reverse_code\",\n",
    "                \"vehicle_category\",\n",
    "                \"vehicle_class_code_primary_scheme\",\n",
    "                \"vehicle_class_code_secondary_scheme\",\n",
    "                \"vehicle_speed\",\n",
    "                \"vehicle_length\",\n",
    "                \"site_occupancy_time_in_milliseconds\",\n",
    "                \"chassis_height_code\",\n",
    "                \"vehicle_following_code\",\n",
    "                \"vehicle_tag_code\",\n",
    "                \"trailer_count\",\n",
    "            ]\n",
    "            ddf = pd.concat(\n",
    "                [\n",
    "                    ddf,\n",
    "                    pd.DataFrame(\n",
    "                        columns=[\n",
    "                            \"axle_count\",\n",
    "                            \"bumper_to_1st_axle_spacing\",\n",
    "                            \"sub_data_type_code_sx\",\n",
    "                            \"number_of_axles_spacings_counted\",\n",
    "                        ]\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        elif data[1].isin(['19']).all():\n",
    "            ddf = data.iloc[:, 4:22]\n",
    "            ddf = pd.DataFrame(ddf).dropna(axis=1, how=\"all\")\n",
    "            ddf.columns = [\n",
    "                \"departure_date\",\n",
    "                \"departure_time\",\n",
    "                \"assigned_lane_number\",\n",
    "                \"physical_lane_number\",\n",
    "                \"forward_reverse_code\",\n",
    "                \"vehicle_category\",\n",
    "                \"vehicle_class_code_primary_scheme\",\n",
    "                \"vehicle_class_code_secondary_scheme\",\n",
    "                \"vehicle_speed\",\n",
    "                \"vehicle_length\",\n",
    "                \"site_occupancy_time_in_milliseconds\",\n",
    "                \"chassis_height_code\",\n",
    "                \"vehicle_following_code\",\n",
    "                \"vehicle_tag_code\",\n",
    "                \"trailer_count\", \n",
    "                \"axle_count\",\n",
    "                \"bumper_to_1st_axle_spacing\",\n",
    "                \"sub_data_type_code_sx\",\n",
    "                \"number_of_axles_spacings_counted\",\n",
    "            ]\n",
    "            ddf[\"number_of_axles_spacings_counted\"] = ddf[\n",
    "                \"number_of_axles_spacings_counted\"\n",
    "            ].astype(int)\n",
    "            for i in range(ddf[\"number_of_axles_spacings_counted\"].max()()):\n",
    "                i = i + 1\n",
    "                newcolumn = (\n",
    "                    \"axle_spacing_\" + str(i) + \"_between_individual_axles_cm\"\n",
    "                )\n",
    "                ddf[newcolumn] = data[22 + i]\n",
    "\n",
    "        ddf = ddf.fillna(0)\n",
    "        ddf[\"assigned_lane_number\"] = ddf[\"assigned_lane_number\"].astype(int)\n",
    "        max_lanes = ddf[\"assigned_lane_number\"].max()\n",
    "        try:\n",
    "            ddf[\"direction\"] = ddf.apply(\n",
    "            lambda x: \"P\" if x[\"assigned_lane_number\"] <= (int(max_lanes) / 2) else \"N\",\n",
    "            axis=1,\n",
    "        )\n",
    "            direction = dfh2.loc[dfh2[0] == \"L1\", 1:3]\n",
    "            direction = direction.drop_duplicates()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ddf[\"forward_direction_code\"] = ddf.apply(\n",
    "                lambda x: get_direction(x[\"assigned_lane_number\"], direction), axis=1\n",
    "            )\n",
    "            # FIXME: ddf['lane_position_code']=ddf.apply(lambda x: Data.get_lane_position(x['lane_number'],direction),axis=1)\n",
    "        except Exception:\n",
    "            ddf[\"forward_direction_code\"] = None\n",
    "            # ddf['lane_position_code']=None\n",
    "\n",
    "        if ddf[\"departure_date\"].map(len).isin([8]).all():\n",
    "            ddf[\"start_datetime\"] = pd.to_datetime(\n",
    "                ddf[\"departure_date\"] + ddf[\"departure_time\"],\n",
    "                format=\"%Y%m%d%H%M%S%f\",\n",
    "            )\n",
    "        elif ddf[\"departure_date\"].map(len).isin([6]).all():\n",
    "            ddf[\"start_datetime\"] = pd.to_datetime(\n",
    "                ddf[\"departure_date\"] + ddf[\"departure_time\"],\n",
    "                format=\"%y%m%d%H%M%S%f\",\n",
    "            )\n",
    "        ddf['year'] = ddf['start_datetime'].dt.year\n",
    "        t1 = dfh2.loc[dfh2[0] == \"S0\", 1].unique()\n",
    "        ddf[\"site_id\"] = str(t1[0])\n",
    "        ddf[\"site_id\"] = ddf[\"site_id\"].astype(str)\n",
    "        ddf['departure_time'] = pd.to_datetime(ddf['departure_time'], format='%H%M%S%f')\n",
    "\n",
    "        # ddf.iloc[:, 2:17] = ddf.iloc[:, 2:17].apply(to_numeric)\n",
    "        # ddf[21] = ddf[21].astype(str)\n",
    "        # ddf.iloc[:, 2:17] = ddf.iloc[:, 2:17].apply(to_numeric)\n",
    "        # ddf = ddf.drop([\"departure_time\"], axis=1)\n",
    "\n",
    "        ddf = ddf.drop_duplicates()\n",
    "        ddf[\"start_datetime\"] = ddf[\"start_datetime\"].astype(\"datetime64[ns]\")\n",
    "    \n",
    "        return ddf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0013-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0131-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0123-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0009-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0073-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0108-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0123-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0123-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0337-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0313-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0323-20211231.RSV\n",
      "data empty\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0108-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0127-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0313-20211231.RSV\n",
      "data empty\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0323-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0700-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0006-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0353-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0072-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0350-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0141-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0353-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0009-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0200-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0323-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0400-20220222.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0313-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0013-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0073-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\1699-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0095-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0045-20220104.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0044-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0151-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0141-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0350-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0048-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0131-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0095-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0700-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0072-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0108-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0006-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0006-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0045-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0288-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\1738-20220131.RSV\n",
      "data empty\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\1699-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0065-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0169-20220228.RSV\n",
      "data empty\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0169-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0131-20220131.RSV\n",
      "data empty\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0073-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0141-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0009-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\1738-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0013-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0041-20211231.RSV\n",
      "data empty\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0353-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0288-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0127-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0161-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0041-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0072-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0065-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0288-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\1699-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0044-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0169-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0065-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0048-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0337-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\1738-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0200-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0350-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0041-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0151-20220131.RSV\n",
      "data empty\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0337-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0700-20220228.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0151-20211231.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0200-20220131.RSV\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0095-20211231.RSV\n"
     ]
    }
   ],
   "source": [
    "files = [i for i in files if i not in donelist]\n",
    "for f in files:\n",
    "    df = to_df(f)\n",
    "    data = dtype10(df)\n",
    "    # header = headers(get_head(df))\n",
    "    # header[\"document_url\"] = str(files)\n",
    "    # data = data_join(data, header)\n",
    "    # data.drop(\"station_name\", axis=1, inplace=True)\n",
    "    # push_to_db(\n",
    "    #         data,\n",
    "    #         \"electronic_count_data_type_10\",\n",
    "    #         [\"site_id\", \"start_datetime\", \"lane_number\"],\n",
    "    #     )\n",
    "    try:\n",
    "        data.to_sql(\n",
    "                \"electronic_count_data_type_10\",\n",
    "                con=config.ENGINE,\n",
    "                schema=\"trafc\",\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "                method=psql_insert_copy,\n",
    "            )\n",
    "        print('done with: ' + f)\n",
    "        donelist.append(f)\n",
    "    except:\n",
    "        pass\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [i for i in files if i not in donelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "            os.path.expanduser(r\"S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\done_files.csv\"),\n",
    "            \"a\",\n",
    "            newline=\"\",\n",
    "        ) as f:\n",
    "            write = csv.writer(f)\n",
    "            write.writerows([[donelist]])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af8b1e165c1ff2d014348c231bd068624d4f3d6b612700b0d12a9816f8e61c96"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
