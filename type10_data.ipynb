{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rsa_data as rd\n",
    "import config\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from io import StringIO\n",
    "import csv\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "src = r\"S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\"\n",
    "test1 = r\"S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0006-20211231.RSV\"\n",
    "problem_files = ['S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0133-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0597-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0133-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0263-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0597-20220227.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0133-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0597-20220131.RSV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE10_DATA_COLUMN_NAMES = ['site_id', 'header_id', \"year\", 'number_of_fields_associated_with_the_basic_vehicle_data', 'data_source_code', 'edit_code', 'departure_date', 'departure_time', 'assigned_lane_number', 'physical_lane_number', 'forward_reverse_code', 'vehicle_category', 'vehicle_class_code_primary_scheme', 'vehicle_class_code_secondary_scheme', 'vehicle_speed', 'vehicle_length', 'site_occupancy_time_in_milliseconds', 'chassis_height_code', 'vehicle_following_code', 'vehicle_tag_code', 'trailer_count', 'axle_count', 'bumper_to_1st_axle_spacing', 'tyre_type', 'sub_data_type_code_vx', 'vehicle_registration_number', 'number_of_images', 'image_name_1', 'image_name_2', 'image_name_3', \n",
    "'sub_data_type_code_sx', 'number_of_axles_spacings_counted', 'axle_spacing_1_between_individual_axles_cm', 'axle_spacing_2_between_individual_axles_cm', 'axle_spacing_3_between_individual_axles_cm', 'axle_spacing_4_between_individual_axles_cm', 'axle_spacing_5_between_individual_axles_cm', 'axle_spacing_6_between_individual_axles_cm', 'axle_spacing_7_between_individual_axles_cm', 'axle_spacing_8_between_individual_axles_cm',\n",
    "'start_datetime', 'direction', 'forward_direction_code', \n",
    "'sub_data_type_code_wx', 'number_of_wheel_masses', 'offset_sensor_detesction_code', 'mass_measurement_resolution', 'wheel_mass_for_wheel_1', 'wheel_mass_for_wheel_2', 'wheel_mass_for_wheel_3', 'wheel_mass_for_wheel_4', 'wheel_mass_for_wheel_5', 'wheel_mass_for_wheel_6', 'wheel_mass_for_wheel_7', 'wheel_mass_for_wheel_8', 'wheel_mass_for_wheel_9', 'wheel_mass_for_wheel_10'\n",
    "]\n",
    "\n",
    "TYPE10_HEADER_COLUMN_NAMES = ['header_id', 'data_description', 'vehicle_classification_scheme_primary', 'vehicle_classification_scheme_secondary', 'maximum_gap_milliseconds', 'maximum_differential_speed'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfiles(path: str):\n",
    "    print(\"COLLECTING FILES......\")\n",
    "    src = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if (\n",
    "                name.endswith(\".RSA\")\n",
    "                or name.endswith(\".rsa\")\n",
    "                or name.endswith(\".rsv\")\n",
    "                or name.endswith(\".RSV\")\n",
    "            ):\n",
    "                p = os.path.join(root, name)\n",
    "                src.append(p)\n",
    "    src = list(set(src))\n",
    "    return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(file: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(file, header=None, sep=\" \", low_memory=False)\n",
    "    df = df[0].str.split(\"\\s+|,\\s+|,\", expand=True)\n",
    "    df = pd.DataFrame(df)\n",
    "    return df\n",
    "\n",
    "def push_to_db(df, table, subset) -> None:\n",
    "    try:\n",
    "        df.to_sql(\n",
    "            table,\n",
    "            con=config.ENGINE,\n",
    "            schema=\"trafc\",\n",
    "            if_exists=\"append\",\n",
    "            index=False,\n",
    "            method=psql_insert_copy,\n",
    "        )\n",
    "    except Exception:\n",
    "        df = df.drop_duplicates(subset=subset)\n",
    "        df.to_sql(\n",
    "            table,\n",
    "            con=config.ENGINE,\n",
    "            schema=\"trafc\",\n",
    "            if_exists=\"append\",\n",
    "            index=False,\n",
    "            method=psql_insert_copy,\n",
    "        )\n",
    "\n",
    "\n",
    "def psql_insert_copy(table, conn, keys, data_iter):\n",
    "    \"\"\"\n",
    "    Execute SQL statement inserting data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    table : pandas.io.sql.SQLTable\n",
    "    conn : sqlalchemy.engine.Engine or sqlalchemy.engine.Connection\n",
    "    keys : list of str\n",
    "        Column names\n",
    "    data_iter : Iterable that iterates the values to be inserted\n",
    "    \"\"\"\n",
    "    # gets a DBAPI connection that can provide a cursor\n",
    "    dbapi_conn = conn.connection\n",
    "    with dbapi_conn.cursor() as cur:\n",
    "        s_buf = StringIO()\n",
    "        writer = csv.writer(s_buf)\n",
    "        writer.writerows(data_iter)\n",
    "        s_buf.seek(0)\n",
    "\n",
    "        columns = \", \".join('\"{}\"'.format(k) for k in keys)\n",
    "        if table.schema:\n",
    "            table_name = \"{}.{}\".format(table.schema, table.name)\n",
    "        else:\n",
    "            table_name = table.name\n",
    "\n",
    "        sql = \"COPY {} ({}) FROM STDIN WITH CSV\".format(table_name, columns)\n",
    "        cur.copy_expert(sql=sql, file=s_buf)\n",
    "\n",
    "def join(header: pd.DataFrame, data: pd.DataFrame) -> pd.DataFrame:\n",
    "    if data.empty:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        q = \"\"\"\n",
    "\t\tSELECT header.header_id, header.station_name, data.*\n",
    "\t\tFROM header\n",
    "\t\tLEFT JOIN data ON data.start_datetime WHERE data.start_datetime >= header.start_datetime AND data.end_datetime <= header.end_datetime;\n",
    "\t\t\"\"\"\n",
    "        q2 = \"\"\"UPDATE data set header_id = (SELECT header_id from header WHERE data.start_datetime >= header.start_datetime AND data.counttime_end <= header.enddate)\"\"\"\n",
    "        pysqldf = lambda q: sqldf(q, globals())\n",
    "        df = sqldf(q, locals())\n",
    "        df = pd.DataFrame(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def data_join(data: pd.DataFrame, header: pd.DataFrame) -> pd.DataFrame:\n",
    "    if data is None:\n",
    "        pass\n",
    "    elif data.empty:\n",
    "        pass\n",
    "    else:\n",
    "        data = pd.DataFrame(data)\n",
    "        data = join(header, data)\n",
    "    return data\n",
    "\n",
    "def get_direction(lane_number, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        filt = df[1] == lane_number\n",
    "        df = df.where(filt)\n",
    "        df = df[2].dropna()\n",
    "        df = int(df)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLLECTING FILES......\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MB2705851\\OneDrive - Surbana Jurong Private Limited\\1_Coding\\GitHub\\brandtosaurus\\traffic_electronic_count_ETL\\type10_data.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000004?line=0'>1</a>\u001b[0m files \u001b[39m=\u001b[39m getfiles(problem_files)\n",
      "\u001b[1;32mc:\\Users\\MB2705851\\OneDrive - Surbana Jurong Private Limited\\1_Coding\\GitHub\\brandtosaurus\\traffic_electronic_count_ETL\\type10_data.ipynb Cell 3'\u001b[0m in \u001b[0;36mgetfiles\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000002?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCOLLECTING FILES......\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000002?line=2'>3</a>\u001b[0m src \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000002?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m root, dirs, files \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mwalk(path):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000002?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m files:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000002?line=5'>6</a>\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000002?line=6'>7</a>\u001b[0m             name\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.RSA\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000002?line=7'>8</a>\u001b[0m             \u001b[39mor\u001b[39;00m name\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.rsa\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000002?line=8'>9</a>\u001b[0m             \u001b[39mor\u001b[39;00m name\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.rsv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000002?line=9'>10</a>\u001b[0m             \u001b[39mor\u001b[39;00m name\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.RSV\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000002?line=10'>11</a>\u001b[0m         ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py:342\u001b[0m, in \u001b[0;36mwalk\u001b[1;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/MB2705851/AppData/Local/Programs/Python/Python310/lib/os.py?line=282'>283</a>\u001b[0m \u001b[39m\"\"\"Directory tree generator.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/MB2705851/AppData/Local/Programs/Python/Python310/lib/os.py?line=283'>284</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/MB2705851/AppData/Local/Programs/Python/Python310/lib/os.py?line=284'>285</a>\u001b[0m \u001b[39mFor each directory in the directory tree rooted at top (including top\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/MB2705851/AppData/Local/Programs/Python/Python310/lib/os.py?line=338'>339</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/MB2705851/AppData/Local/Programs/Python/Python310/lib/os.py?line=339'>340</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/MB2705851/AppData/Local/Programs/Python/Python310/lib/os.py?line=340'>341</a>\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m\"\u001b[39m\u001b[39mos.walk\u001b[39m\u001b[39m\"\u001b[39m, top, topdown, onerror, followlinks)\n\u001b[1;32m--> <a href='file:///c%3A/Users/MB2705851/AppData/Local/Programs/Python/Python310/lib/os.py?line=341'>342</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _walk(fspath(top), topdown, onerror, followlinks)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list"
     ]
    }
   ],
   "source": [
    "files = getfiles(problem_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0127-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0133-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0597-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0133-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0263-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0597-20220227.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0133-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0597-20220131.RSV']\n"
     ]
    }
   ],
   "source": [
    "print(problem_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "donelist = ['S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\n7-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\x013-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\x0b1-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\n3-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\x009-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\x073-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\x088-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\n3-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\n3-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\x1b7-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\x193-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\x1a3-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0013-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0131-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0123-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0009-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0073-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0108-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0123-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0123-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0337-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0313-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0323-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0108-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0127-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0313-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0323-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0700-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0006-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0353-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0072-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0350-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0141-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0353-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0009-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0200-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0323-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0400-20220222.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0313-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0013-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0073-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\1699-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0095-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0045-20220104.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0044-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0151-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0141-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0350-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0048-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0131-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0095-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0700-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0072-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0108-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0006-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0006-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0045-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0288-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\1738-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\1699-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0065-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0169-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0169-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0131-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0073-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0141-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0009-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\1738-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0013-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0041-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0353-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0288-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0127-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0161-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0041-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0072-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0065-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0288-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\1699-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0044-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0169-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0065-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0048-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0337-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\1738-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0200-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0350-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0041-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0151-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0337-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0700-20220228.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0151-20211231.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0200-20220131.RSV', 'S:\\\\Michael Brandt\\\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\\\0095-20211231.RSV']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_head' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MB2705851\\OneDrive - Surbana Jurong Private Limited\\1_Coding\\GitHub\\brandtosaurus\\traffic_electronic_count_ETL\\type10_data.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000007?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m df[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms+|,\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms+|,\u001b[39m\u001b[39m\"\u001b[39m, expand\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000007?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(df)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000007?line=4'>5</a>\u001b[0m dfh \u001b[39m=\u001b[39m get_head(df)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000007?line=5'>6</a>\u001b[0m header \u001b[39m=\u001b[39m headers(dfh)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/type10_data.ipynb#ch0000007?line=6'>7</a>\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_head' is not defined"
     ]
    }
   ],
   "source": [
    "for file in problem_files:\n",
    "    df = pd.read_csv(file, header=None, sep=\" \", low_memory=False)\n",
    "    df = df[0].str.split(\"\\s+|,\\s+|,\", expand=True)\n",
    "    df = pd.DataFrame(df)\n",
    "    dfh = get_head(df)\n",
    "    header = headers(dfh)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head(df) -> pd.DataFrame:\n",
    "    dfh = pd.DataFrame(\n",
    "        df.loc[\n",
    "            (df[0].isin([\"H0\", \"S0\", \"I0\", \"S1\", \"D0\", \"D1\", \"D3\", \"L0\", \"L1\"]))\n",
    "            | (\n",
    "                (df[0].isin([\"21\", \"70\", \"30\", \"13\", \"60\"]))\n",
    "                & (~df[1].isin([\"0\", \"1\", \"2\", \"3\", \"4\"]))\n",
    "            )\n",
    "            | (\n",
    "                (df[0].isin([\"10\"]))\n",
    "                & (df[1].isin([\"1\", \"8\", \"5\", \"01\", \"08\", \"05\"]))\n",
    "            )\n",
    "        ]\n",
    "    ).dropna(axis=1, how=\"all\")\n",
    "    dfh[\"index\"] = dfh.index\n",
    "    breaks = dfh[\"index\"].diff() != 1\n",
    "    groups = breaks.cumsum()\n",
    "    dfh[\"newindex\"] = groups\n",
    "    dfh = dfh.set_index(\"newindex\")\n",
    "    dfh = dfh.drop(columns=[\"index\"])\n",
    "    return dfh\n",
    "\n",
    "def headers(dfh: pd.DataFrame) -> pd.DataFrame:\n",
    "    if not dfh.empty:\n",
    "        headers = pd.DataFrame()\n",
    "        headers[\"site_id\"] = dfh.loc[dfh[0] == \"S0\", 1].astype(str)\n",
    "        if not dfh.loc[dfh[0] == \"S1\", 1:].empty:\n",
    "            headers[\"station_name\"] = (\n",
    "                dfh.loc[dfh[0] == \"S1\", 1:]\n",
    "                .dropna(axis=1)\n",
    "                .apply(\" \".join, axis=1)\n",
    "                .astype(str)\n",
    "            )\n",
    "        else:\n",
    "            headers[\"station_name\"] = (\n",
    "                dfh.loc[dfh[0] == \"S0\", 2:]\n",
    "                .dropna(axis=1)\n",
    "                .apply(\" \".join, axis=1)\n",
    "                .astype(str)\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            headers[\"y\"] = dfh.loc[dfh[0] == \"S0\", 5].astype(float)\n",
    "            headers[\"x\"] = dfh.loc[dfh[0] == \"S0\", 6].astype(float)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        headers[\"number_of_lanes\"] = dfh.loc[dfh[0] == \"L0\", 2].astype(int)\n",
    "\n",
    "        try:\n",
    "            headers[\"speedbin1\"] = dfh.loc[dfh[0] == \"21\", 4].astype(int)\n",
    "            headers[\"speedbin2\"] = dfh.loc[dfh[0] == \"21\", 5].astype(int)\n",
    "            headers[\"speedbin3\"] = dfh.loc[dfh[0] == \"21\", 6].astype(int)\n",
    "            headers[\"speedbin4\"] = dfh.loc[dfh[0] == \"21\", 7].astype(int)\n",
    "            headers[\"speedbin5\"] = dfh.loc[dfh[0] == \"21\", 8].astype(int)\n",
    "            headers[\"speedbin6\"] = dfh.loc[dfh[0] == \"21\", 9].astype(int)\n",
    "            headers[\"speedbin7\"] = dfh.loc[dfh[0] == \"21\", 10].astype(int)\n",
    "            headers[\"speedbin8\"] = dfh.loc[dfh[0] == \"21\", 11].astype(int)\n",
    "            headers[\"speedbin9\"] = dfh.loc[dfh[0] == \"21\", 12].astype(int)\n",
    "            headers[\"type_21_count_interval_minutes\"] = dfh.loc[\n",
    "                dfh[0] == \"21\", 1\n",
    "            ].astype(int)\n",
    "            headers[\"type_21_programmable_rear_to_rear_headway_bin\"] = dfh.loc[\n",
    "                dfh[0] == \"21\", 3\n",
    "            ].astype(int)\n",
    "            headers[\"type_21_program_id\"] = \"2\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            headers[\"type_10_vehicle_classification_scheme_primary\"] = dfh.loc[\n",
    "                dfh[0] == \"10\", 1\n",
    "            ].astype(int)\n",
    "            headers[\"type_10_vehicle_classification_scheme_secondary\"] = dfh.loc[\n",
    "                dfh[0] == \"10\", 2\n",
    "            ].astype(int)\n",
    "            headers[\"type_10_maximum_gap_milliseconds\"] = dfh.loc[\n",
    "                dfh[0] == \"10\", 3\n",
    "            ].astype(int)\n",
    "            headers[\"type_10_maximum_differential_speed\"] = dfh.loc[\n",
    "                dfh[0] == \"10\", 4\n",
    "            ].astype(int)\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            headers[\"type_30_summary_interval_minutes\"] = dfh.loc[\n",
    "                dfh[0] == \"30\", 2\n",
    "            ].astype(int)\n",
    "            headers[\"type_30_vehicle_classification_scheme\"] = dfh.loc[\n",
    "                dfh[0] == \"30\", 3\n",
    "            ].astype(int)\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            headers[\"type_70_summary_interval_minutes\"] = dfh.loc[\n",
    "                dfh[0] == \"70\", 1\n",
    "            ].astype(int)\n",
    "            headers[\"type_70_vehicle_classification_scheme\"] = dfh.loc[\n",
    "                dfh[0] == \"70\", 2\n",
    "            ].astype(int)\n",
    "            headers[\"type_70_maximum_gap_milliseconds\"] = dfh.loc[\n",
    "                dfh[0] == \"70\", 3\n",
    "            ].astype(int)\n",
    "            headers[\"type_70_maximum_differential_speed\"] = dfh.loc[\n",
    "                dfh[0] == \"70\", 4\n",
    "            ].astype(int)\n",
    "            headers[\"type_70_error_bin_code\"] = dfh.loc[dfh[0] == \"70\", 5].astype(\n",
    "                int\n",
    "            )\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if not dfh.loc[dfh[0] == \"D3\", 1].empty:\n",
    "            headers[\"start_datetime\"] = dfh.loc[dfh[0] == \"D3\", 1].astype(str)\n",
    "            headers[\"start_time\"] = dfh.loc[dfh[0] == \"D3\", 2].astype(str)\n",
    "            headers[\"end_datetime\"] = dfh.loc[dfh[0] == \"D3\", 3].astype(str)\n",
    "            headers[\"end_time\"] = dfh.loc[dfh[0] == \"D3\", 4].astype(str)\n",
    "        else:\n",
    "            headers[\"start_datetime\"] = dfh.loc[dfh[0] == \"D1\", 1].astype(str)\n",
    "            headers[\"start_time\"] = dfh.loc[dfh[0] == \"D1\", 2].astype(str)\n",
    "            headers[\"end_datetime\"] = dfh.loc[dfh[0] == \"D1\", 3].astype(str)\n",
    "            headers[\"end_time\"] = dfh.loc[dfh[0] == \"D1\", 4].astype(str)\n",
    "\n",
    "        # headers[\"end_datetime\"] = headers.apply(\n",
    "        #     lambda x: pd.to_datetime(\n",
    "        #         x[\"end_datetime\"] + x[\"end_time\"], format=\"%y%m%d%H%M%S\"\n",
    "        #     )\n",
    "        #     if (\n",
    "        #         x[\"end_time\"] != \"240000\"\n",
    "        #         and len(x[\"end_datetime\"]) == 6\n",
    "        #         and len(x[\"end_time\"]) == 6\n",
    "        #     )\n",
    "        #     else (\n",
    "        #         pd.to_datetime(\n",
    "        #             x[\"end_datetime\"] + x[\"end_time\"], format=\"%y%m%d%H%M%S%f\"\n",
    "        #         )\n",
    "        #         if (\n",
    "        #             x[\"end_time\"] != \"24000000\"\n",
    "        #             and len(x[\"end_datetime\"]) == 6\n",
    "        #             and len(x[\"end_time\"]) == 8\n",
    "        #         )\n",
    "        #         else (\n",
    "        #             pd.to_datetime(\n",
    "        #                 x[\"end_datetime\"] + x[\"end_time\"], format=\"%Y%m%d%H%M%S\"\n",
    "        #             )\n",
    "        #             if (\n",
    "        #                 x[\"end_time\"] != \"240000\"\n",
    "        #                 and len(x[\"end_datetime\"]) == 8\n",
    "        #                 and len(x[\"end_time\"]) == 6\n",
    "        #             )\n",
    "        #             else (\n",
    "        #                 pd.to_datetime(\n",
    "        #                     x[\"end_datetime\"] + x[\"end_time\"],\n",
    "        #                     format=\"%Y%m%d%H%M%S%f\",\n",
    "                        # )\n",
    "                        # if (\n",
    "                        #     x[\"end_time\"] != \"24000000\"\n",
    "                        #     and len(x[\"end_datetime\"]) == 8\n",
    "                        #     and len(x[\"end_time\"]) == 8\n",
    "                        # )\n",
    "                        # else (\n",
    "                        #     pd.to_datetime(x[\"end_datetime\"], format=\"%y%m%d\")\n",
    "                        #     + timedelta(days=1)\n",
    "                        #     if (\n",
    "                        #         x[\"end_time\"] == \"240000\"\n",
    "                        #         and len(x[\"end_datetime\"]) == 6\n",
    "                            #     and len(x[\"end_time\"]) == 6\n",
    "                            # )\n",
    "                            # else (\n",
    "                            #     pd.to_datetime(x[\"end_datetime\"], format=\"%y%m%d\")\n",
    "                            #     + timedelta(days=1)\n",
    "                            #     if (\n",
    "                            #         x[\"end_time\"] == \"24000000\"\n",
    "                            #         and len(x[\"end_datetime\"]) == 6\n",
    "                            #         and len(x[\"end_time\"]) == 8\n",
    "                            #     )\n",
    "                            #     else (\n",
    "                            #         pd.to_datetime(\n",
    "                            #             x[\"end_datetime\"], format=\"%Y%m%d\"\n",
    "                            #         )\n",
    "                            #         + timedelta(days=1)\n",
    "                            #         if (\n",
    "                            #             x[\"end_time\"] == \"240000\"\n",
    "                                #         and len(x[\"end_datetime\"]) == 8\n",
    "                                #         and len(x[\"end_time\"]) == 6\n",
    "                                #     )\n",
    "                                #     else (\n",
    "                                #         pd.to_datetime(\n",
    "                                #             x[\"end_datetime\"], format=\"%Y%m%d\"\n",
    "                                #         )\n",
    "                                #         + timedelta(days=1)\n",
    "                                #         if (\n",
    "                                #             x[\"end_time\"] == \"24000000\"\n",
    "                                #             and len(x[\"end_datetime\"]) == 8\n",
    "                                #             and len(x[\"end_time\"]) == 8\n",
    "                                #         )\n",
    "                                #         else pd.to_datetime(\n",
    "                                #             x[\"end_datetime\"] + x[\"end_time\"]\n",
    "                                #         )\n",
    "                                #     )\n",
    "                                # )\n",
    "        #                     )\n",
    "        #                 )\n",
    "        #             )\n",
    "        #         )\n",
    "        #     ),\n",
    "        #     axis=1,\n",
    "        # )\n",
    "\n",
    "        # headers[\"start_datetime\"] = headers.apply(\n",
    "        #     lambda x: pd.to_datetime(\n",
    "        #         x[\"start_datetime\"] + x[\"start_time\"], format=\"%y%m%d%H%M%S\"\n",
    "        #     )\n",
    "        #     if (\n",
    "        #         x[\"start_time\"] != \"240000\"\n",
    "        #         and len(x[\"start_datetime\"]) == 6\n",
    "        #         and len(x[\"start_time\"]) == 6\n",
    "        #     )\n",
    "        #     else (\n",
    "        #         pd.to_datetime(\n",
    "        #             x[\"start_datetime\"] + x[\"start_time\"], format=\"%y%m%d%H%M%S%f\"\n",
    "        #         )\n",
    "        #         if (\n",
    "        #             x[\"start_time\"] != \"24000000\"\n",
    "        #             and len(x[\"start_datetime\"]) == 6\n",
    "        #             and len(x[\"start_time\"]) == 8\n",
    "        #         )\n",
    "        #         else (\n",
    "        #             pd.to_datetime(\n",
    "        #                 x[\"start_datetime\"] + x[\"start_time\"], format=\"%Y%m%d%H%M%S\"\n",
    "        #             )\n",
    "        #             if (\n",
    "        #                 x[\"start_time\"] != \"240000\"\n",
    "        #                 and len(x[\"start_datetime\"]) == 8\n",
    "                    #     and len(x[\"start_time\"]) == 6\n",
    "                    # )\n",
    "                    # else (\n",
    "                    #     pd.to_datetime(\n",
    "                    #         x[\"start_datetime\"] + x[\"start_time\"],\n",
    "                    #         format=\"%Y%m%d%H%M%S%f\",\n",
    "                    #     )\n",
    "                    #     if (\n",
    "                    #         x[\"start_time\"] != \"24000000\"\n",
    "                    #         and len(x[\"start_datetime\"]) == 8\n",
    "                    #         and len(x[\"start_time\"]) == 8\n",
    "                    #     )\n",
    "                    #     else (\n",
    "                    #         pd.to_datetime(x[\"start_datetime\"], format=\"%y%m%d\")\n",
    "                    #         + timedelta(days=1)\n",
    "                    #         if (\n",
    "                    #             x[\"start_time\"] == \"240000\"\n",
    "                    #             and len(x[\"start_datetime\"]) == 6\n",
    "                    #             and len(x[\"start_time\"]) == 6\n",
    "                    #         )\n",
    "                            # else (\n",
    "                            #     pd.to_datetime(x[\"start_datetime\"], format=\"%y%m%d\")\n",
    "                            #     + timedelta(days=1)\n",
    "                            #     if (\n",
    "                            #         x[\"start_time\"] == \"24000000\"\n",
    "                            #         and len(x[\"start_datetime\"]) == 6\n",
    "                            #         and len(x[\"start_time\"]) == 8\n",
    "                            #     )\n",
    "                            #     else (\n",
    "                            #         pd.to_datetime(\n",
    "                            #             x[\"start_datetime\"], format=\"%Y%m%d\"\n",
    "                            #         )\n",
    "                            #         + timedelta(days=1)\n",
    "                            #         if (\n",
    "                            #             x[\"start_time\"] == \"240000\"\n",
    "                            #             and len(x[\"start_datetime\"]) == 8\n",
    "                            #             and len(x[\"start_time\"]) == 6\n",
    "                            #         )\n",
    "        #                             else (\n",
    "        #                                 pd.to_datetime(\n",
    "        #                                     x[\"start_datetime\"], format=\"%Y%m%d\"\n",
    "        #                                 )\n",
    "        #                                 + timedelta(days=1)\n",
    "        #                                 if (\n",
    "        #                                     x[\"start_time\"] == \"24000000\"\n",
    "        #                                     and len(x[\"start_datetime\"]) == 8\n",
    "        #                                     and len(x[\"start_time\"]) == 8\n",
    "        #                                 )\n",
    "        #                                 else pd.to_datetime(\n",
    "        #                                     x[\"start_datetime\"] + x[\"start_time\"]\n",
    "        #                                 )\n",
    "        #                             )\n",
    "        #                         )\n",
    "        #                     )\n",
    "        #                 )\n",
    "        #             )\n",
    "        #         )\n",
    "        #     ),\n",
    "        #     axis=1,\n",
    "        # )\n",
    "\n",
    "        # headers = headers.drop([\"start_time\"], axis=1)\n",
    "        # headers = headers.drop([\"end_time\"], axis=1)\n",
    "\n",
    "        # headers[\"start_datetime\"] = pd.to_datetime(headers[\"start_datetime\"])\n",
    "        # headers[\"end_datetime\"] = pd.to_datetime(headers[\"end_datetime\"])\n",
    "        headers[\"site_id\"] = headers[\"site_id\"].astype(str)\n",
    "\n",
    "        try:\n",
    "            headers[\"instrumentation_description\"] = (\n",
    "                dfh.loc[dfh[0] == \"I0\", 1:]\n",
    "                .dropna(axis=1)\n",
    "                .apply(\" \".join, axis=1)\n",
    "                .astype(str)\n",
    "            )\n",
    "        except Exception:\n",
    "            headers[\"instrumentation_description\"] = None\n",
    "\n",
    "        try:\n",
    "            headers[\"type_30_summary_interval_minutes\"] = headers[\n",
    "                \"type_21_count_interval_minutes\"\n",
    "            ]\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            headers[\"type_70_summary_interval_minutes\"] = headers[\n",
    "                \"type_21_count_interval_minutes\"\n",
    "            ]\n",
    "            headers[\"type_70_vehicle_classification_scheme\"] = headers[\n",
    "                \"type_21_count_interval_minutes\"\n",
    "            ]\n",
    "            headers[\"type_70_vehicle_classification_scheme\"] = headers[\n",
    "                \"type_21_count_interval_minutes\"\n",
    "            ]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        headers = headers.fillna(method=\"ffill\")\n",
    "        headers = headers.fillna(method=\"bfill\")\n",
    "\n",
    "        headers = headers.drop_duplicates(ignore_index=True)\n",
    "\n",
    "        headers[\"header_id\"] = \"\"\n",
    "        headers[\"header_id\"] = headers[\"header_id\"].apply(\n",
    "            lambda x: str(uuid.uuid4())\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    return headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = to_df(r\"S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0133-20220228.RSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.loc[(df[0] == \"10\") & (df[1].isin([\"15\", \"17\", \"19\", \"18\"]))].dropna(\n",
    "        axis=1, how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data[1].isin([\"18\"]).all():\n",
    "    ddf = data.iloc[:, 4:20]\n",
    "    ddf = pd.DataFrame(ddf).dropna(axis=1, how=\"all\")\n",
    "    ddf.columns = [\n",
    "        \"departure_date\",\n",
    "        \"departure_time\",\n",
    "        \"assigned_lane_number\",\n",
    "        \"physical_lane_number\",\n",
    "        \"forward_reverse_code\",\n",
    "        \"vehicle_category\",\n",
    "        \"vehicle_class_code_primary_scheme\",\n",
    "        \"vehicle_class_code_secondary_scheme\",\n",
    "        \"vehicle_speed\",\n",
    "        \"vehicle_length\",\n",
    "        \"site_occupancy_time_in_milliseconds\",\n",
    "        \"chassis_height_code\",\n",
    "        \"vehicle_following_code\",\n",
    "        \"vehicle_tag_code\",\n",
    "        \"trailer_count\", \n",
    "        \"axle_count\",\n",
    "    ]\n",
    "    ddf = pd.concat(\n",
    "                    [\n",
    "                        ddf,\n",
    "                        pd.DataFrame(\n",
    "                            columns=[\n",
    "                                'sub_data_type_code_sx', \n",
    "                                'number_of_axles_spacings_counted', \n",
    "                                'axle_spacing_1_between_individual_axles_cm', \n",
    "                                'axle_spacing_2_between_individual_axles_cm', \n",
    "                                'axle_spacing_3_between_individual_axles_cm', \n",
    "                                'axle_spacing_4_between_individual_axles_cm', \n",
    "                                'axle_spacing_5_between_individual_axles_cm', \n",
    "                                'axle_spacing_6_between_individual_axles_cm', \n",
    "                                'axle_spacing_7_between_individual_axles_cm', \n",
    "                                'axle_spacing_8_between_individual_axles_cm',\n",
    "                                'sub_data_type_code_wx', \n",
    "                                'number_of_wheel_masses', \n",
    "                                'offset_sensor_detesction_code', \n",
    "                                'mass_measurement_resolution', \n",
    "                                'wheel_mass_for_wheel_1', \n",
    "                                'wheel_mass_for_wheel_2', \n",
    "                                'wheel_mass_for_wheel_3', \n",
    "                                'wheel_mass_for_wheel_4', \n",
    "                                'wheel_mass_for_wheel_5', \n",
    "                                'wheel_mass_for_wheel_6', \n",
    "                                'wheel_mass_for_wheel_7', \n",
    "                                'wheel_mass_for_wheel_8', \n",
    "                                'wheel_mass_for_wheel_9', \n",
    "                                'wheel_mass_for_wheel_10'\n",
    "                            ]\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "sx_columns = ['sub_data_type_code_sx', \n",
    "    'number_of_axles_spacings_counted', \n",
    "    'axle_spacing_1_between_individual_axles_cm', \n",
    "    'axle_spacing_2_between_individual_axles_cm', \n",
    "    'axle_spacing_3_between_individual_axles_cm', \n",
    "    'axle_spacing_4_between_individual_axles_cm', \n",
    "    'axle_spacing_5_between_individual_axles_cm', \n",
    "    'axle_spacing_6_between_individual_axles_cm', \n",
    "    'axle_spacing_7_between_individual_axles_cm', \n",
    "    'axle_spacing_8_between_individual_axles_cm',\n",
    "    ]\n",
    "wx_columns = ['sub_data_type_code_wx', \n",
    "    'number_of_wheel_masses', \n",
    "    'offset_sensor_detesction_code', \n",
    "    'mass_measurement_resolution', \n",
    "    'wheel_mass_for_wheel_1', \n",
    "    'wheel_mass_for_wheel_2', \n",
    "    'wheel_mass_for_wheel_3', \n",
    "    'wheel_mass_for_wheel_4', \n",
    "    'wheel_mass_for_wheel_5', \n",
    "    'wheel_mass_for_wheel_6', \n",
    "    'wheel_mass_for_wheel_7', \n",
    "    'wheel_mass_for_wheel_8', \n",
    "    'wheel_mass_for_wheel_9', \n",
    "    'wheel_mass_for_wheel_10'\n",
    "    ]\n",
    "ddf = ddf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf['idx']=ddf.index\n",
    "# ddf=ddf.set_index('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MB2705851\\AppData\\Local\\Temp\\ipykernel_11980\\4042383144.py:16: FutureWarning: Passing 'suffixes' which cause duplicate columns {'axle_spacing_4_between_individual_axles_cm_x', 'axle_spacing_3_between_individual_axles_cm_x', 'axle_spacing_2_between_individual_axles_cm_x', 'axle_spacing_1_between_individual_axles_cm_x', 'number_of_axles_spacings_counted_x', 'sub_data_type_code_sx_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  ddf = ddf.merge(ddf2, how='left', on='idx')\n",
      "C:\\Users\\MB2705851\\AppData\\Local\\Temp\\ipykernel_11980\\4042383144.py:16: FutureWarning: Passing 'suffixes' which cause duplicate columns {'axle_spacing_2_between_individual_axles_cm_x', 'axle_spacing_1_between_individual_axles_cm_x', 'number_of_axles_spacings_counted_x', 'sub_data_type_code_sx_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  ddf = ddf.merge(ddf2, how='left', on='idx')\n",
      "C:\\Users\\MB2705851\\AppData\\Local\\Temp\\ipykernel_11980\\4042383144.py:16: FutureWarning: Passing 'suffixes' which cause duplicate columns {'axle_spacing_4_between_individual_axles_cm_x', 'axle_spacing_3_between_individual_axles_cm_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  ddf = ddf.merge(ddf2, how='left', on='idx')\n",
      "C:\\Users\\MB2705851\\AppData\\Local\\Temp\\ipykernel_11980\\4042383144.py:16: FutureWarning: Passing 'suffixes' which cause duplicate columns {'axle_spacing_2_between_individual_axles_cm_x', 'axle_spacing_1_between_individual_axles_cm_x', 'number_of_axles_spacings_counted_x', 'sub_data_type_code_sx_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  ddf = ddf.merge(ddf2, how='left', on='idx')\n",
      "C:\\Users\\MB2705851\\AppData\\Local\\Temp\\ipykernel_11980\\4042383144.py:16: FutureWarning: Passing 'suffixes' which cause duplicate columns {'axle_spacing_5_between_individual_axles_cm_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  ddf = ddf.merge(ddf2, how='left', on='idx')\n"
     ]
    }
   ],
   "source": [
    "for idx, row in data.iterrows():\n",
    "    id = int(row[21]) + 22\n",
    "    ddf2 = pd.DataFrame([row[20:id].tolist()], index=[idx])\n",
    "    cols = []\n",
    "    for i in range(ddf2.shape[1]):\n",
    "        if i == 0:\n",
    "            cols.append('sub_data_type_code_sx')\n",
    "        elif i == 1:\n",
    "            cols.append(\"number_of_axles_spacings_counted\")\n",
    "        else:\n",
    "            cols.append('axle_spacing_'+ str(i-1) + \"_between_individual_axles_cm\")\n",
    "    ddf2 = pd.DataFrame([row[20:id].tolist()], columns=cols)\n",
    "    ddf2['idx'] = idx\n",
    "    # ddf2 = ddf2.set_index('idx')\n",
    "    # ddf = pd.concat([ddf,ddf2], axis= 0)\n",
    "    ddf = ddf.merge(ddf2, how='left', on='idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['departure_date', 'departure_time', 'assigned_lane_number',\n",
       "       'physical_lane_number', 'forward_reverse_code', 'vehicle_category',\n",
       "       'vehicle_class_code_primary_scheme',\n",
       "       'vehicle_class_code_secondary_scheme', 'vehicle_speed',\n",
       "       'vehicle_length', 'site_occupancy_time_in_milliseconds',\n",
       "       'chassis_height_code', 'vehicle_following_code', 'vehicle_tag_code',\n",
       "       'trailer_count', 'axle_count', 'idx', 'sub_data_type_code_sx_x',\n",
       "       'number_of_axles_spacings_counted_x',\n",
       "       'axle_spacing_1_between_individual_axles_cm_x',\n",
       "       'axle_spacing_2_between_individual_axles_cm_x',\n",
       "       'axle_spacing_3_between_individual_axles_cm_x',\n",
       "       'axle_spacing_4_between_individual_axles_cm_x',\n",
       "       'sub_data_type_code_sx_y', 'number_of_axles_spacings_counted_y',\n",
       "       'axle_spacing_1_between_individual_axles_cm_y',\n",
       "       'axle_spacing_2_between_individual_axles_cm_y',\n",
       "       'axle_spacing_3_between_individual_axles_cm_y',\n",
       "       'axle_spacing_4_between_individual_axles_cm_y',\n",
       "       'sub_data_type_code_sx_x', 'number_of_axles_spacings_counted_x',\n",
       "       'axle_spacing_1_between_individual_axles_cm_x',\n",
       "       'axle_spacing_2_between_individual_axles_cm_x',\n",
       "       'axle_spacing_3_between_individual_axles_cm_x',\n",
       "       'axle_spacing_4_between_individual_axles_cm_x',\n",
       "       'axle_spacing_5_between_individual_axles_cm_x',\n",
       "       'axle_spacing_6_between_individual_axles_cm_x',\n",
       "       'sub_data_type_code_sx_y', 'number_of_axles_spacings_counted_y',\n",
       "       'axle_spacing_1_between_individual_axles_cm_y',\n",
       "       'axle_spacing_2_between_individual_axles_cm_y',\n",
       "       'axle_spacing_3_between_individual_axles_cm_y',\n",
       "       'axle_spacing_4_between_individual_axles_cm_y',\n",
       "       'axle_spacing_5_between_individual_axles_cm_y',\n",
       "       'sub_data_type_code_sx_x', 'number_of_axles_spacings_counted_x',\n",
       "       'axle_spacing_1_between_individual_axles_cm_x',\n",
       "       'axle_spacing_2_between_individual_axles_cm_x',\n",
       "       'sub_data_type_code_sx_y', 'number_of_axles_spacings_counted_y',\n",
       "       'axle_spacing_1_between_individual_axles_cm_y',\n",
       "       'axle_spacing_2_between_individual_axles_cm_y',\n",
       "       'axle_spacing_3_between_individual_axles_cm_x',\n",
       "       'axle_spacing_4_between_individual_axles_cm_x',\n",
       "       'sub_data_type_code_sx_x', 'number_of_axles_spacings_counted_x',\n",
       "       'axle_spacing_1_between_individual_axles_cm_x',\n",
       "       'axle_spacing_2_between_individual_axles_cm_x',\n",
       "       'axle_spacing_3_between_individual_axles_cm_y',\n",
       "       'axle_spacing_4_between_individual_axles_cm_y',\n",
       "       'axle_spacing_5_between_individual_axles_cm_x',\n",
       "       'sub_data_type_code_sx_y', 'number_of_axles_spacings_counted_y',\n",
       "       'axle_spacing_1_between_individual_axles_cm_y',\n",
       "       'axle_spacing_2_between_individual_axles_cm_y', 'sub_data_type_code_sx',\n",
       "       'number_of_axles_spacings_counted',\n",
       "       'axle_spacing_1_between_individual_axles_cm',\n",
       "       'axle_spacing_2_between_individual_axles_cm',\n",
       "       'axle_spacing_3_between_individual_axles_cm',\n",
       "       'axle_spacing_4_between_individual_axles_cm',\n",
       "       'axle_spacing_5_between_individual_axles_cm_y',\n",
       "       'axle_spacing_6_between_individual_axles_cm_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axle_spacing_0\n",
      "axle_spacing_1\n",
      "axle_spacing_2\n",
      "axle_spacing_3\n",
      "axle_spacing_4\n"
     ]
    }
   ],
   "source": [
    "for idx, row in data.iterrows():\n",
    "    id = int(row[19]) + 21\n",
    "    ddf2 = pd.DataFrame([row[id:].tolist()], index=[idx])\n",
    "    cols = []\n",
    "    for i in range(ddf2.shape[1]):\n",
    "        if i == 0:\n",
    "            cols.append('sub_data_type_code_wx')\n",
    "        elif i == 1:\n",
    "            cols.append(\"number_of_wheel_masses\")\n",
    "        elif i == 2:\n",
    "            cols.append(\"offset_sensor_detesction_code\")\n",
    "        elif i == 3:\n",
    "            cols.append(\"mass_measurement_resolution\")\n",
    "        else:\n",
    "            cols.append('wheel_mass_for_wheel_'+ str(i - 3))\n",
    "    ddf2 = pd.DataFrame([row[20:id].tolist()], columns=cols)\n",
    "    ddf2['idx'] = idx\n",
    "    ddf2.set_index('idx')\n",
    "    join_df = join_df.join(ddf,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtype10(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    data = df.loc[(df[0] == \"10\") & (df[1].isin([\"15\", \"17\", \"19\", \"18\"]))].dropna(\n",
    "        axis=1, how=\"all\"\n",
    "    )\n",
    "    dfh2 = pd.DataFrame(df.loc[(df[0].isin([\"S0\", \"L1\"]))]).dropna(\n",
    "        axis=1, how=\"all\"\n",
    "    )\n",
    "    if data.empty:\n",
    "        print(\"data empty\")\n",
    "        print(data)\n",
    "    else:\n",
    "        ddf = data.iloc[:, 4:]\n",
    "        ddf = pd.DataFrame(ddf).dropna(axis=1, how=\"all\")\n",
    "        if (data[1].isin(['15','17']).all()\n",
    "            and len(ddf.columns) == 11\n",
    "        ):\n",
    "            ddf.columns = [\n",
    "                \"departure_date\",\n",
    "                \"departure_time\",\n",
    "                \"assigned_lane_number\",\n",
    "                \"physical_lane_number\",\n",
    "                \"forward_reverse_code\",\n",
    "                \"vehicle_category\",\n",
    "                \"vehicle_class_code_primary_scheme\",\n",
    "                \"vehicle_class_code_secondary_scheme\",\n",
    "                \"vehicle_speed\",\n",
    "                \"vehicle_length\",\n",
    "                \"site_occupancy_time_in_milliseconds\",\n",
    "                \"chassis_height_code\",\n",
    "                \"vehicle_following_code\",\n",
    "            ]\n",
    "            ddf = pd.concat(\n",
    "                [\n",
    "                    ddf,\n",
    "                    pd.DataFrame(\n",
    "                        columns=[\n",
    "                            \"vehicle_tag_code\",\n",
    "                            \"trailer_count\",\n",
    "                            \"axle_count\",\n",
    "                            \"bumper_to_1st_axle_spacing\",\n",
    "                            \"sub_data_type_code_sx\",\n",
    "                            \"number_of_axles_spacings_counted\",\n",
    "                        ]\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        elif (data[1].isin(['15','17']).all()\n",
    "            and len(ddf.columns) == 13\n",
    "        ):\n",
    "            ddf.columns = [\n",
    "                \"departure_date\",\n",
    "                \"departure_time\",\n",
    "                \"assigned_lane_number\",\n",
    "                \"physical_lane_number\",\n",
    "                \"forward_reverse_code\",\n",
    "                \"vehicle_category\",\n",
    "                \"vehicle_class_code_primary_scheme\",\n",
    "                \"vehicle_class_code_secondary_scheme\",\n",
    "                \"vehicle_speed\",\n",
    "                \"vehicle_length\",\n",
    "                \"site_occupancy_time_in_milliseconds\",\n",
    "                \"chassis_height_code\",\n",
    "                \"vehicle_following_code\",\n",
    "            ]\n",
    "            ddf = pd.concat(\n",
    "                [\n",
    "                    ddf,\n",
    "                    pd.DataFrame(\n",
    "                        columns=[\n",
    "                            \"vehicle_tag_code\",\n",
    "                            \"trailer_count\",\n",
    "                            \"axle_count\",\n",
    "                            \"bumper_to_1st_axle_spacing\",\n",
    "                            \"sub_data_type_code_sx\",\n",
    "                            \"number_of_axles_spacings_counted\",\n",
    "                        ]\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        elif (data[1].isin(['15','17']).all()\n",
    "            and len(ddf.columns) == 15\n",
    "        ):\n",
    "            ddf.columns = [\n",
    "                \"departure_date\",\n",
    "                \"departure_time\",\n",
    "                \"assigned_lane_number\",\n",
    "                \"physical_lane_number\",\n",
    "                \"forward_reverse_code\",\n",
    "                \"vehicle_category\",\n",
    "                \"vehicle_class_code_primary_scheme\",\n",
    "                \"vehicle_class_code_secondary_scheme\",\n",
    "                \"vehicle_speed\",\n",
    "                \"vehicle_length\",\n",
    "                \"site_occupancy_time_in_milliseconds\",\n",
    "                \"chassis_height_code\",\n",
    "                \"vehicle_following_code\",\n",
    "                \"vehicle_tag_code\",\n",
    "                \"trailer_count\",\n",
    "            ]\n",
    "            ddf = pd.concat(\n",
    "                [\n",
    "                    ddf,\n",
    "                    pd.DataFrame(\n",
    "                        columns=[\n",
    "                            \"axle_count\",\n",
    "                            \"bumper_to_1st_axle_spacing\",\n",
    "                            \"sub_data_type_code_sx\",\n",
    "                            \"number_of_axles_spacings_counted\",\n",
    "                        ]\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        elif data[1].isin([\"19\"]).all():\n",
    "            ddf = data.iloc[:, 4:22]\n",
    "            ddf = pd.DataFrame(ddf).dropna(axis=1, how=\"all\")\n",
    "            ddf.columns = [\n",
    "                \"departure_date\",\n",
    "                \"departure_time\",\n",
    "                \"assigned_lane_number\",\n",
    "                \"physical_lane_number\",\n",
    "                \"forward_reverse_code\",\n",
    "                \"vehicle_category\",\n",
    "                \"vehicle_class_code_primary_scheme\",\n",
    "                \"vehicle_class_code_secondary_scheme\",\n",
    "                \"vehicle_speed\",\n",
    "                \"vehicle_length\",\n",
    "                \"site_occupancy_time_in_milliseconds\",\n",
    "                \"chassis_height_code\",\n",
    "                \"vehicle_following_code\",\n",
    "                \"vehicle_tag_code\",\n",
    "                \"trailer_count\", \n",
    "                \"axle_count\",\n",
    "                \"bumper_to_1st_axle_spacing\",\n",
    "                \"sub_data_type_code_sx\",\n",
    "                \"number_of_axles_spacings_counted\",\n",
    "            ]\n",
    "            ddf[\"number_of_axles_spacings_counted\"] = ddf[\n",
    "                \"number_of_axles_spacings_counted\"\n",
    "            ].astype(int)\n",
    "            for i in range(ddf[\"number_of_axles_spacings_counted\"].max()()):\n",
    "                i = i + 1\n",
    "                newcolumn = (\n",
    "                    \"axle_spacing_\" + str(i) + \"_between_individual_axles_cm\"\n",
    "                )\n",
    "                ddf[newcolumn] = data[22 + i]\n",
    "        \n",
    "        elif data[1].isin([\"18\"]).all():\n",
    "            ddf = data.iloc[:, 4:20]\n",
    "            ddf = pd.DataFrame(ddf).dropna(axis=1, how=\"all\")\n",
    "            ddf.columns = [\n",
    "                \"departure_date\",\n",
    "                \"departure_time\",\n",
    "                \"assigned_lane_number\",\n",
    "                \"physical_lane_number\",\n",
    "                \"forward_reverse_code\",\n",
    "                \"vehicle_category\",\n",
    "                \"vehicle_class_code_primary_scheme\",\n",
    "                \"vehicle_class_code_secondary_scheme\",\n",
    "                \"vehicle_speed\",\n",
    "                \"vehicle_length\",\n",
    "                \"site_occupancy_time_in_milliseconds\",\n",
    "                \"chassis_height_code\",\n",
    "                \"vehicle_following_code\",\n",
    "                \"vehicle_tag_code\",\n",
    "                \"trailer_count\", \n",
    "                \"axle_count\",\n",
    "            ]\n",
    "            for idx, row in data.iterrows():\n",
    "                id = int(row[19]) + 21\n",
    "                ddf2 = pd.DataFrame([row[20:id].tolist()], index=[idx])\n",
    "                ddf3 = pd.DataFrame([row[id:].tolist()], index=[idx])\n",
    "                cols = []\n",
    "                for i in range(ddf2.shape[1]):\n",
    "                    if i == 0:\n",
    "                        cols.append('sub_data_type_code')\n",
    "                    elif i == 1:\n",
    "                        cols.append(\"number_of_axles_spacings\")\n",
    "                    else:\n",
    "                        cols.append('axle_spacing_'+ str(i - 1))\n",
    "                    ddf2 = pd.DataFrame([row[20:].tolist()], columns=cols)\n",
    "                    ddf2['idx'] = idx\n",
    "                    ddf2.set_index('idx')\n",
    "                    ddf = ddf.join(ddf2,how='outer')\n",
    "                \n",
    "                for i in range(ddf3.shape[1]):\n",
    "                    if i == 0:\n",
    "                        cols.append('sub_data_type_code_wx')\n",
    "                    elif i == 1:\n",
    "                        cols.append(\"number_of_wheel_masses\")\n",
    "                    elif i == 2:\n",
    "                        cols.append(\"offset_sensor_detesction_code\")\n",
    "                    elif i == 3:\n",
    "                        cols.append(\"mass_measurement_resolution\")\n",
    "                    else:\n",
    "                        cols.append('wheel_mass_for_wheel_'+ str(i - 3))\n",
    "                    ddf3 = pd.DataFrame([row[20:].tolist()], columns=cols)\n",
    "                    ddf3['idx'] = idx\n",
    "                    ddf3.set_index('idx')\n",
    "                    ddf = ddf.join(ddf3,how='outer')\n",
    " \n",
    "        ddf = ddf.fillna(0)\n",
    "        ddf[\"assigned_lane_number\"] = ddf[\"assigned_lane_number\"].astype(int)\n",
    "        max_lanes = ddf[\"assigned_lane_number\"].max()\n",
    "        try:\n",
    "            ddf[\"direction\"] = ddf.apply(\n",
    "            lambda x: \"P\" if x[\"assigned_lane_number\"] <= (int(max_lanes) / 2) else \"N\",\n",
    "            axis=1,\n",
    "        )\n",
    "            direction = dfh2.loc[dfh2[0] == \"L1\", 1:3]\n",
    "            direction = direction.drop_duplicates()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ddf[\"forward_direction_code\"] = ddf.apply(\n",
    "                lambda x: get_direction(x[\"assigned_lane_number\"], direction), axis=1\n",
    "            )\n",
    "            # FIXME: ddf['lane_position_code']=ddf.apply(lambda x: Data.get_lane_position(x['lane_number'],direction),axis=1)\n",
    "        except Exception:\n",
    "            ddf[\"forward_direction_code\"] = None\n",
    "            # ddf['lane_position_code']=None\n",
    "\n",
    "        if ddf[\"departure_date\"].map(len).isin([8]).all():\n",
    "            ddf[\"start_datetime\"] = pd.to_datetime(\n",
    "                ddf[\"departure_date\"] + ddf[\"departure_time\"],\n",
    "                format=\"%Y%m%d%H%M%S%f\",\n",
    "            )\n",
    "        elif ddf[\"departure_date\"].map(len).isin([6]).all():\n",
    "            ddf[\"start_datetime\"] = pd.to_datetime(\n",
    "                ddf[\"departure_date\"] + ddf[\"departure_time\"],\n",
    "                format=\"%y%m%d%H%M%S%f\",\n",
    "            )\n",
    "        ddf['year'] = ddf['start_datetime'].dt.year\n",
    "        t1 = dfh2.loc[dfh2[0] == \"S0\", 1].unique()\n",
    "        ddf[\"site_id\"] = str(t1[0])\n",
    "        ddf[\"site_id\"] = ddf[\"site_id\"].astype(str)\n",
    "        ddf['departure_time'] = pd.to_datetime(ddf['departure_time'], format='%H%M%S%f')\n",
    "\n",
    "        ddf = ddf.drop_duplicates()\n",
    "        ddf[\"start_datetime\"] = ddf[\"start_datetime\"].astype(\"datetime64[ns]\")\n",
    "    \n",
    "        return ddf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0       1        2       3        4        5        6     7     8   \\\n",
      "0      H0       1      320       3      RSA     None     None  None  None   \n",
      "1      S0    0133     0133     R25     None     None     None  None  None   \n",
      "2      I0   00001   RT8000    None     None     None     None  None  None   \n",
      "3      D0       M        L    None     None     None     None  None  None   \n",
      "4      D1  220201  0000000  220228  2400000   211026  1229000  None  None   \n",
      "...    ..     ...      ...     ...      ...      ...      ...   ...   ...   \n",
      "39674  10      18        1       0   220228  2317566        1     1     1   \n",
      "39675  10      18        1       0   220228  2348178        2     2     1   \n",
      "39676  10      18        1       0   220228  2349547        1     1     1   \n",
      "39677  10      18        1       0   220228  2350337        1     1     1   \n",
      "39678  10      18        1       0   220228  2354026        1     1     1   \n",
      "\n",
      "         9     10    11    12    13    14    15    16    17    18    19    20  \\\n",
      "0      None  None  None  None  None  None  None  None  None  None  None  None   \n",
      "1      None  None  None  None  None  None  None  None  None  None  None  None   \n",
      "2      None  None  None  None  None  None  None  None  None  None  None  None   \n",
      "3      None  None  None  None  None  None  None  None  None  None  None  None   \n",
      "4      None  None  None  None  None  None  None  None  None  None  None  None   \n",
      "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "39674    23     5     2    71   820           1     1           0     2    sA   \n",
      "39675    23     5     2    76   960           1     1           0     2    sA   \n",
      "39676    24    16     4    50  2190           1     1           1     7    sA   \n",
      "39677    27    12     4    79  1770           2     1           1     5    sA   \n",
      "39678    27    12     4    59  1860           2     1           1     5    sA   \n",
      "\n",
      "         21    22    23    24    25    26    27     28    29    30    31  \\\n",
      "0      None  None  None  None  None  None  None   None  None  None  None   \n",
      "1      None  None  None  None  None  None  None   None  None  None  None   \n",
      "2      None  None  None  None  None  None  None   None  None  None  None   \n",
      "3      None  None  None  None  None  None  None   None  None  None  None   \n",
      "4      None  None  None  None  None  None  None   None  None  None  None   \n",
      "...     ...   ...   ...   ...   ...   ...   ...    ...   ...   ...   ...   \n",
      "39674     1   423    W1     2              2214   4384  None  None  None   \n",
      "39675     1   551    W1     2              4008  11384  None  None  None   \n",
      "39676     6   473   132   365   132   616   130     W1     7               \n",
      "39677     4   330   135   909   133    W1     5               5065  1852   \n",
      "39678     4   308   129   902   134    W1     5               5846  7163   \n",
      "\n",
      "         32    33    34    35    36    37    38    39    40    41    42    43  \\\n",
      "0      None  None  None  None  None  None  None  None  None  None  None  None   \n",
      "1      None  None  None  None  None  None  None  None  None  None  None  None   \n",
      "2      None  None  None  None  None  None  None  None  None  None  None  None   \n",
      "3      None  None  None  None  None  None  None  None  None  None  None  None   \n",
      "4      None  None  None  None  None  None  None  None  None  None  None  None   \n",
      "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "39674  None  None  None  None  None  None  None  None  None  None  None  None   \n",
      "39675  None  None  None  None  None  None  None  None  None  None  None  None   \n",
      "39676  7351  5296  4182  6931  7814  8031  7018  None  None  None  None  None   \n",
      "39677  1679  6121  4515  None  None  None  None  None  None  None  None  None   \n",
      "39678  6642  5397  5397  None  None  None  None  None  None  None  None  None   \n",
      "\n",
      "         44    45    46    47    48    49    50    51    52    53    54  \n",
      "0      None  None  None  None  None  None  None  None  None  None  None  \n",
      "1      None  None  None  None  None  None  None  None  None  None  None  \n",
      "2      None  None  None  None  None  None  None  None  None  None  None  \n",
      "3      None  None  None  None  None  None  None  None  None  None  None  \n",
      "4      None  None  None  None  None  None  None  None  None  None  None  \n",
      "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "39674  None  None  None  None  None  None  None  None  None  None  None  \n",
      "39675  None  None  None  None  None  None  None  None  None  None  None  \n",
      "39676  None  None  None  None  None  None  None  None  None  None  None  \n",
      "39677  None  None  None  None  None  None  None  None  None  None  None  \n",
      "39678  None  None  None  None  None  None  None  None  None  None  None  \n",
      "\n",
      "[39679 rows x 55 columns]\n",
      "data empty\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "done with: S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\0133-20220228.RSV\n"
     ]
    }
   ],
   "source": [
    "# files = [i for i in problem_files if i not in donelist]\n",
    "for f in problem_files:\n",
    "    df = to_df(f)\n",
    "    print(df)\n",
    "    data = dtype10(df)\n",
    "    # header = headers(get_head(df))\n",
    "    # header[\"document_url\"] = str(files)\n",
    "    # data = data_join(data, header)\n",
    "    # data.drop(\"station_name\", axis=1, inplace=True)\n",
    "    # push_to_db(\n",
    "    #         data,\n",
    "    #         \"electronic_count_data_type_10\",\n",
    "    #         [\"site_id\", \"start_datetime\", \"lane_number\"],\n",
    "    #     )\n",
    "    # data.to_sql(\n",
    "    #             \"electronic_count_data_type_10\",\n",
    "    #             con=config.ENGINE,\n",
    "    #             schema=\"trafc\",\n",
    "    #             if_exists=\"append\",\n",
    "    #             index=False,\n",
    "    #             method=psql_insert_copy,\n",
    "    #         )\n",
    "    print('done with: ' + f)\n",
    "    donelist.append(f)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_sql(\n",
    "                \"electronic_count_data_type_10\",\n",
    "                con=config.ENGINE,\n",
    "                schema=\"trafc\",\n",
    "                if_exists=\"append\",\n",
    "                index=False,\n",
    "                method=psql_insert_copy,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "            os.path.expanduser(r\"S:\\Michael Brandt\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22\\done_files.csv\"),\n",
    "            \"a\",\n",
    "            newline=\"\",\n",
    "        ) as f:\n",
    "            write = csv.writer(f)\n",
    "            write.writerows([[donelist]])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af8b1e165c1ff2d014348c231bd068624d4f3d6b612700b0d12a9816f8e61c96"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
