{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from datetime import timedelta, date\n",
    "import uuid\n",
    "import traceback\n",
    "\n",
    "# import rsa_data_summary as rd\n",
    "# import rsa_data_wim as wim\n",
    "# import rsa_headers as rh\n",
    "import config\n",
    "import queries as q\n",
    "import tools\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"C:\\PQ410\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path: str):\n",
    "    \"\"\"\n",
    "    It takes a list of files, checks if they are in a zip file, if not, it gets the files from the\n",
    "    directory, if they are in a zip file, it exits. \n",
    "\n",
    "    Then it checks if the file exists, if not, it creates it. \n",
    "\n",
    "    Then it reads the file, if it can't read it, it creates an empty list. \n",
    "\n",
    "    Then it checks if the files are in the list, if they are, it removes them. \n",
    "\n",
    "    Then it checks if the directory exists, if not, it creates it. \n",
    "\n",
    "    Then it checks if the file exists, if not, it creates it. \n",
    "\n",
    "    Then it returns the list of files.\n",
    "\n",
    "    :param files: str = \"C:/Users/user/Desktop/files\"\n",
    "    :type files: str\n",
    "    :return: A list of files that are not in the fileComplete list.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(os.path.expanduser(config.PATH)):\n",
    "        os.makedirs(os.path.expanduser(config.PATH))\n",
    "\n",
    "    if not os.path.exists(os.path.expanduser(config.FILES_COMPLETE)):\n",
    "        with open(\n",
    "                os.path.expanduser(config.FILES_COMPLETE), \"w\",) as f:\n",
    "            pass\n",
    "\n",
    "    if not os.path.exists(os.path.expanduser(config.PATH)):\n",
    "        with open(os.path.expanduser(config.FILES_FAILED), \"w\",) as f:\n",
    "            pass\n",
    "\n",
    "    file_complete = pd.read_csv(config.FILES_COMPLETE, header=None)\n",
    "    file_complete = file_complete[0].tolist()\n",
    "\n",
    "    if tools.is_zip(path) == False:\n",
    "        files = tools.get_files(path)\n",
    "    else:\n",
    "        raise SystemExit\n",
    "\n",
    "    files = [i for i in files if i not in file_complete]\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting files\n",
      "COLLECTING FILES......\n"
     ]
    }
   ],
   "source": [
    "files = get_files(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting files\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\MB2705851\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\MB2705851\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\MB2705851\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MB2705851\\OneDrive - Surbana Jurong Private Limited\\1_Coding\\GitHub\\brandtosaurus\\traffic_electronic_count_ETL\\test.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/test.ipynb#ch0000027?line=11'>12</a>\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/test.ipynb#ch0000027?line=13'>14</a>\u001b[0m file_complete \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(config\u001b[39m.\u001b[39mFILES_COMPLETE)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/test.ipynb#ch0000027?line=14'>15</a>\u001b[0m file_complete \u001b[39m=\u001b[39m file_complete[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/test.ipynb#ch0000027?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m tools\u001b[39m.\u001b[39mis_zip(path) \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/test.ipynb#ch0000027?line=17'>18</a>\u001b[0m     files \u001b[39m=\u001b[39m tools\u001b[39m.\u001b[39mget_files(path)\n",
      "File \u001b[1;32mc:\\Users\\MB2705851\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\MB2705851\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "    print(\"getting files\")\n",
    "    if not os.path.exists(os.path.expanduser(config.PATH)):\n",
    "        os.makedirs(os.path.expanduser(config.PATH))\n",
    "\n",
    "    if not os.path.exists(os.path.expanduser(config.FILES_COMPLETE)):\n",
    "        with open(\n",
    "                os.path.expanduser(config.FILES_COMPLETE), \"w\",) as f:\n",
    "            pass\n",
    "\n",
    "    if not os.path.exists(os.path.expanduser(config.PATH)):\n",
    "        with open(os.path.expanduser(config.FILES_FAILED), \"w\",) as f:\n",
    "            pass\n",
    "\n",
    "    files_complete = pd.read_csv(config.FILES_COMPLETE, header=None)\n",
    "    files_complete = file_complete[0].tolist()\n",
    "\n",
    "    if tools.is_zip(path) == False:\n",
    "        files = tools.get_files(path)\n",
    "    else:\n",
    "        raise SystemExit\n",
    "\n",
    "    files = [i for i in files if i not in file_complete]\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER_IDS_FOR_UPDATE_MAIN_WITH_T30 = \"\"\"SELECT header_id FROM trafc.electronic_count_data_partitioned p WHERE exists(\n",
    "    SELECT id FROM trafc.electronic_count_data_type_30 t30 WHERE t30.header_id = p.header_id\n",
    "    and p.light_motor_vehicles is null\n",
    "    limit 1\n",
    "    )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_ids = list(pd.read_sql(HEADER_IDS_FOR_UPDATE_MAIN_WITH_T30, config.ENGINE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MB2705851\\OneDrive - Surbana Jurong Private Limited\\1_Coding\\GitHub\\brandtosaurus\\traffic_electronic_count_ETL\\test.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/test.ipynb#ch0000008?line=8'>9</a>\u001b[0m new_test \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mPQ410\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2 - Data In\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mTIS Data\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDisks Sept 2020\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mData Discs\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2017\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2017Q2\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mHistoric\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mGPG CTO 2011 Yearbook\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mRSA Data\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m0317.rsa\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/test.ipynb#ch0000008?line=9'>10</a>\u001b[0m another_test \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mPQ410\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2 - Data In\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mTIS Data\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mCSIR\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2010\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mPermanent HSWIM\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m0087_2010.rsa\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/test.ipynb#ch0000008?line=10'>11</a>\u001b[0m empty \u001b[39m=\u001b[39m r\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "# individual tables for type 30 and 60 test\n",
    "# files = tools.getfiles(r'C:\\FTP\\Syntell\\SMEC RSA Files_GP PRM Sites_Dec21toFeb22')\n",
    "test_header = r\"C:\\PQ410\\2 - Data In\\TIS Data\\CSIR\\2010\\Secondary Loop\\0007.rsa\"\n",
    "file = r\"C:\\PQ410\\2 - Data In\\TIS Data\\GDRT\\GP_RSA 2014\\0038.RSA\"\n",
    "t21_file =r\"C:\\Users\\MB2705851\\OneDrive - Surbana Jurong Private Limited\\Manuals & Guidelines\\Traffic\\example data\\type21_1.RSA\"\n",
    "t10_file = r\"C:\\FTP\\Syntell\\SMEC RSV Files_GP PRM Sites_Dec21toFeb22_individuals\\0400-20220222.RSV\"\n",
    "t10_file2 = r\"C:\\Users\\MB2705851\\OneDrive - Surbana Jurong Private Limited\\Manuals & Guidelines\\Traffic\\example data\\type21_60_70.RSA\"\n",
    "type60_file = r\"C:\\Users\\MB2705851\\OneDrive - Surbana Jurong Private Limited\\Manuals & Guidelines\\Traffic\\example data\\type21_60_70.RSA\"\n",
    "new_test = r\"C:\\PQ410\\2 - Data In\\TIS Data\\Disks Sept 2020\\Data Discs\\2017\\2017Q2\\Historic\\GPG CTO 2011 Yearbook\\RSA Data\\0317.rsa\"\n",
    "another_test = r\"C:\\PQ410\\2 - Data In\\TIS Data\\CSIR\\2010\\Permanent HSWIM\\0087_2010.rsa\"\n",
    "empty = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electronic_count_data_type_21_columns = list(pd.read_sql_query(\"SELECT * from trafc.electronic_count_data_type_21 limit 1\",config.ENGINE).columns)\n",
    "# electronic_count_data_type_30_columns = list(pd.read_sql_query(\"SELECT * from trafc.electronic_count_data_type_30 limit 1\",config.ENGINE).columns)\n",
    "# electronic_count_data_type_60_columns = list(pd.read_sql_query(\"SELECT * from trafc.electronic_count_data_type_60 limit 1\",config.ENGINE).columns)\n",
    "# electronic_count_data_type_70_columns = list(pd.read_sql_query(\"SELECT * from trafc.electronic_count_data_type_70 limit 1\",config.ENGINE).columns)\n",
    "# header_columns = list(pd.read_sql_query(\"SELECT * from trafc.electronic_count_header limit 1\",config.ENGINE).columns)\n",
    "vm_limits = pd.read_sql_query(\n",
    "            f\"SELECT * FROM {config.TRAFFIC_LOOKUP_SCHEMA}.gross_vehicle_mass_limits;\"\n",
    "            , config.ENGINE)\n",
    "t10_cols = list(pd.read_sql_query(\n",
    "            q.SELECT_ELECTRONIC_COUNT_DATA_TYPE_10_LIMIT1, config.ENGINE).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = tools.to_df(t10_file)\n",
    "# dfa = pd.read_csv(t10_file, header=None, nrows = 200) #, sep='\\s+', engine='python')\n",
    "dfa = pd.read_csv(another_test, header=None, sep='\\s+\\t', engine='python', nrows = 500)\n",
    "dfa = dfa[0].str.split(\"\\s+|,\\s+|,|;|;\\s+\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dfa.loc[ # data\n",
    "    (~dfa[0].isin([\"H0\", \"H9\", \"S0\", \"I0\", \"S1\", \"D0\", \"D1\", \"D3\", \"L0\", \"L1\"]))\n",
    "    & ((\n",
    "        (dfa[0].isin([\"21\", \"22\", \"70\", \"30\", \"31\", \"13\", \"60\"]))\n",
    "        & (dfa[1].isin([\"0\", \"1\", \"2\", \"3\", \"4\"]))\n",
    "        & (dfa.loc[dfa[0].isin([\"21\", \"70\", \"30\", \"13\", \"60\"]), 3].fillna(\"0\").astype(int) > 80)\n",
    "    ) | (\n",
    "        (dfa[0].isin([\"10\"]))\n",
    "        & (~dfa[1].isin([\"1\", \"8\", \"5\", \"9\", \"01\", \"08\", \"05\", \"09\"]))\n",
    "        & (dfa.loc[dfa[0].isin([\"10\"]), 4].astype(int) > 80)\n",
    "    ))           \n",
    "    ]).dropna(axis=1, how=\"all\").reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_df = pd.DataFrame(dfa.loc[ # header\n",
    "    (dfa[0].isin([\"H0\", \"S0\", \"I0\", \"S1\", \"D0\", \"D1\", \"D3\", \"L0\", \"L1\"]))\n",
    "    | (\n",
    "        (dfa[0].isin([\"21\", \"70\", \"30\", \"13\", \"60\"]))\n",
    "        & (dfa.loc[dfa[0].isin([\"21\", \"70\", \"30\", \"13\", \"60\"])][2].fillna(\"0\").astype(int) < 80)\n",
    "    )\n",
    "    | (\n",
    "        (dfa[0].isin([\"10\"]))\n",
    "        & (dfa[1].isin([\"1\", \"8\", \"5\", \"9\", \"01\", \"08\", \"05\", \"09\"]))\n",
    "    )\n",
    "]).dropna(axis=1, how=\"all\").reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = head_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def header(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "\"\"\"\n",
    "It takes a dataframe, finds the header information, and returns a dataframe with the header\n",
    "information\n",
    "\n",
    ":param df: pd.DataFrame\n",
    ":type df: pd.DataFrame\n",
    ":return: A dataframe\n",
    "\"\"\"\n",
    "df = df.reset_index(drop=True)\n",
    "st_nd = df.loc[df[0].isin([\"D1\", \"D3\"]), 0:4].reset_index(\n",
    "    drop=True).copy()\n",
    "\n",
    "# standard column identifiers\n",
    "st_dt_col = 1\n",
    "end_dt_col = 3\n",
    "st_tme_col = 2\n",
    "end_tme_col = 4\n",
    "\n",
    "# checks for all non numeric characters in the date and removes them\n",
    "st_nd[st_dt_col] = st_nd[st_dt_col].str.extract(\n",
    "    \"(\\d+)\", expand=False)\n",
    "st_nd[end_dt_col] = st_nd[end_dt_col].str.extract(\n",
    "    \"(\\d+)\", expand=False)\n",
    "st_nd[st_tme_col] = st_nd[st_tme_col].str.extract(\n",
    "    \"(\\d+)\", expand=False)\n",
    "st_nd[end_tme_col] = st_nd[end_tme_col].str.extract(\n",
    "    \"(\\d+)\", expand=False)\n",
    "st_nd.loc[st_nd[st_dt_col].str.len() < 6, st_dt_col] = None\n",
    "st_nd.loc[st_nd[end_dt_col].str.len() < 6, end_dt_col] = None\n",
    "\n",
    "# backfills the missing dates with the previous date\n",
    "st_nd[st_dt_col].bfill(inplace=True)\n",
    "st_nd[end_dt_col].bfill(inplace=True)\n",
    "st_nd[st_tme_col].bfill(inplace=True)\n",
    "st_nd[end_tme_col].bfill(inplace=True)\n",
    "\n",
    "# adds century to year if it is not there\n",
    "st_nd[st_dt_col] = st_nd[st_dt_col].apply(\n",
    "    lambda x: str(date.today())[:2] + x if len(x) == 6 and int(x[:2]) <= 50\n",
    "    else str(int(str(date.today())[:2])-1) + x\n",
    "    if len(x) == 6 and int(x[:2]) > 50\n",
    "    else x)\n",
    "st_nd[end_dt_col] = st_nd[end_dt_col].apply(\n",
    "    lambda x: str(date.today())[:2] + x if len(x) == 6 and int(x[:2]) <= 50\n",
    "    else str(int(str(date.today())[:2])-1) + x\n",
    "    if len(x) == 6 and int(x[:2]) > 50\n",
    "    else x)\n",
    "\n",
    "# index 2 and 4 are time, this makes the time uniform length\n",
    "st_nd[st_tme_col] = st_nd[st_tme_col].str.pad(\n",
    "    width=7, side='right', fillchar=\"0\")\n",
    "st_nd[end_tme_col] = st_nd[end_tme_col].str.pad(\n",
    "    width=7, side='right', fillchar=\"0\")\n",
    "\n",
    "# this filters for time = 24H00m and makes it zero hour\n",
    "st_nd[end_tme_col].loc[st_nd[end_tme_col].str[:2]\n",
    "                        == '24'] = ('0').zfill(7)\n",
    "\n",
    "try:  # Looks for invalid date then changes to date format\n",
    "    st_nd[st_dt_col] = st_nd[st_dt_col].apply(\n",
    "        lambda x: pd.to_datetime(str(int(x)+1), format=\"%Y%m%d\")\n",
    "        if x[-2:] == \"00\"\n",
    "        else pd.to_datetime(x, format=\"%Y%m%d\").date())\n",
    "except ValueError:\n",
    "    traceback.print_exc()\n",
    "\n",
    "try:  # adds a day if the hour is zero hour and changes string to datetime.date\n",
    "    st_nd[end_dt_col] = st_nd[end_dt_col].apply(\n",
    "        lambda x: pd.to_datetime(\n",
    "            x[end_dt_col], format=\"%Y%m%d\").date() + timedelta(days=1)\n",
    "        if x[4] == '0'.zfill(7) else pd.to_datetime(x[end_dt_col], format=\"%Y%m%d\").date())\n",
    "except (ValueError, TypeError):\n",
    "    # print(self.file)\n",
    "    st_nd[end_dt_col] = pd.to_datetime(\n",
    "        st_nd[end_dt_col], format=\"%Y%m%d\").dt.date\n",
    "\n",
    "# changes time string into datetime.time\n",
    "try:\n",
    "    st_nd[st_tme_col] = pd.to_datetime(\n",
    "        st_nd[st_tme_col], format=\"%H%M%S%f\").dt.time\n",
    "except ValueError:\n",
    "    st_nd[st_tme_col] = pd.to_datetime(\n",
    "        \"0\".zfill(7), format=\"%H%M%S%f\").strftime(\"%H:%M:%S\")\n",
    "try:\n",
    "    st_nd[end_tme_col] = pd.to_datetime(\n",
    "        st_nd[end_tme_col], format=\"%H%M%S%f\").dt.time\n",
    "except ValueError:\n",
    "    st_nd[end_tme_col] = pd.to_datetime(\n",
    "        \"0\".zfill(7), format=\"%H%M%S%f\").strftime(\"%H:%M:%S\")\n",
    "except:\n",
    "    pass\n",
    "    # raise Exception(f\"\"\"header func: time not working \n",
    "    # - st_nd[st_tme_col] = st_nd[st_tme_col].apply(lambda x: pd.to_datetime(x, format='%H%M%S%f').time())\n",
    "    #     look at file {self.file}\"\"\")\n",
    "\n",
    "# creates start_datetime and end_datetime\n",
    "st_nd[\"start_datetime\"] = pd.to_datetime((st_nd[st_dt_col].astype(\n",
    "    str)+st_nd[st_tme_col].astype(str)), format='%Y-%m-%d%H:%M:%S')\n",
    "st_nd[\"end_datetime\"] = pd.to_datetime((st_nd[end_dt_col].astype(\n",
    "    str)+st_nd[end_tme_col].astype(str)), format='%Y-%m-%d%H:%M:%S')\n",
    "\n",
    "st_nd = st_nd.iloc[:, 1:].drop_duplicates()\n",
    "\n",
    "headers = pd.DataFrame()\n",
    "headers['start_datetime'] = st_nd.groupby(\n",
    "    st_nd['start_datetime'].dt.year).min()['start_datetime']\n",
    "headers['end_datetime'] = st_nd.groupby(\n",
    "    st_nd['end_datetime'].dt.year).max()['end_datetime']\n",
    "\n",
    "# headers['document_url'] = self.file\n",
    "# headers[\"header_id\"] = self.header_id\n",
    "headers['year'] = headers['start_datetime'].dt.year.round().astype(int)\n",
    "headers[\"number_of_lanes\"] = int(df.loc[df[0] == \"L0\", 2].drop_duplicates().reset_index(drop=True).at[0])\n",
    "\n",
    "t21 = df.loc[df[0] == \"21\"].dropna(\n",
    "    axis=1).drop_duplicates().reset_index().copy()\n",
    "t21 = t21.iloc[:, (t21.shape[1])-9:].astype(int)\n",
    "t21.columns = range(t21.columns.size)\n",
    "t21.rename(columns={\n",
    "    0: 'speedbin1',\n",
    "    1: 'speedbin2',\n",
    "    2: 'speedbin3',\n",
    "    3: 'speedbin4',\n",
    "    4: 'speedbin5',\n",
    "    5: 'speedbin6',\n",
    "    6: 'speedbin7',\n",
    "    7: 'speedbin8',\n",
    "    8: 'speedbin9'}, inplace=True)\n",
    "\n",
    "headers = pd.concat([headers, t21], ignore_index=True,\n",
    "                    axis=0).bfill().ffill().drop_duplicates()\n",
    "\n",
    "try:\n",
    "    headers[\"summary_interval_minutes\"] = int(\n",
    "        df.loc[df[0] == \"21\", 1].drop_duplicates().reset_index(drop=True)[0])\n",
    "    headers[\"summary_interval_minutes\"] = int(\n",
    "        df.loc[df[0] == \"21\", 1].drop_duplicates().reset_index(drop=True)[0])\n",
    "    headers[\"summary_interval_minutes\"] = int(\n",
    "        df.loc[df[0] == \"21\", 1].drop_duplicates().reset_index(drop=True)[0])\n",
    "except KeyError:\n",
    "    pass\n",
    "try:\n",
    "    headers[\"summary_interval_minutes\"] = int(\n",
    "        df.loc[df[0] == \"30\", 1].drop_duplicates().reset_index(drop=True)[0])\n",
    "    headers[\"summary_interval_minutes\"] = int(\n",
    "        df.loc[df[0] == \"30\", 1].drop_duplicates().reset_index(drop=True)[0])\n",
    "    headers[\"summary_interval_minutes\"] = int(\n",
    "        df.loc[df[0] == \"30\", 1].drop_duplicates().reset_index(drop=True)[0])\n",
    "    headers[\"vehicle_classification_scheme\"] = int(\n",
    "        df.loc[df[0] == \"30\", 3].drop_duplicates().reset_index(drop=True)[0])\n",
    "except KeyError:\n",
    "    pass\n",
    "try:\n",
    "    headers[\"summary_interval_minutes\"] = int(\n",
    "        df.loc[df[0] == \"70\", 1].drop_duplicates().reset_index(drop=True)[0])\n",
    "    headers[\"summary_interval_minutes\"] = int(\n",
    "        df.loc[df[0] == \"70\", 1].drop_duplicates().reset_index(drop=True)[0])\n",
    "    headers[\"summary_interval_minutes\"] = int(\n",
    "        df.loc[df[0] == \"70\", 1].drop_duplicates().reset_index(drop=True)[0])\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    headers['dir1_id'] = int(df[df[0] == \"L1\"].dropna(\n",
    "        axis=1).drop_duplicates().reset_index(drop=True)[2].min())\n",
    "    headers['dir2_id'] = int(df[df[0] == \"L1\"].dropna(\n",
    "        axis=1).drop_duplicates().reset_index(drop=True)[2].max())\n",
    "except (KeyError, ValueError):\n",
    "    headers['dir1_id'] = 0\n",
    "    headers['dir2_id'] = 4\n",
    "\n",
    "try:\n",
    "    headers[\"vehicle_classification_scheme\"] = int(df.loc[\n",
    "        df[0] == \"70\", 2].drop_duplicates().reset_index(drop=True)[0])\n",
    "    headers[\"maximum_gap_milliseconds\"] = int(df.loc[\n",
    "        df[0] == \"70\", 3].drop_duplicates().reset_index(drop=True)[0])\n",
    "    headers[\"maximum_differential_speed\"] = int(df.loc[\n",
    "        df[0] == \"70\", 4].drop_duplicates().reset_index(drop=True)[0])\n",
    "    headers[\"error_bin_code\"] = int(df.loc[\n",
    "        df[0] == \"70\", 5].drop_duplicates().reset_index(drop=True)[0])\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "headers = headers.reset_index(drop=True)\n",
    "\n",
    "headers['year'] = headers['year'].astype(float).round().astype(int)\n",
    "\n",
    "headers[headers.select_dtypes(include=['object','number']).columns] = headers[\n",
    "    headers.select_dtypes(include=['object','number']).columns].apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "station_name = df.loc[df[0].isin([\"S0\"]), 3:].reset_index(\n",
    "    drop=True).drop_duplicates().dropna(axis=1)\n",
    "headers[\"station_name\"] = station_name[station_name.columns].apply(\n",
    "    lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "    \n",
    "# headers['site_id'] = self.site_id\n",
    "\n",
    "# m = headers.select_dtypes(np.number)\n",
    "# headers[m.columns] = m.round().astype(int)\n",
    "# return headers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers[headers.select_dtypes(include=[np.number]).columns] = headers[\n",
    "    headers.select_dtypes(include=[np.number]).columns].apply(pd.to_numeric, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers[headers.select_dtypes(include=[np.number]).columns] = headers[\n",
    "    headers.select_dtypes(include=[np.number]).columns].astype(float).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_datetime                   datetime64[ns]\n",
       "end_datetime                     datetime64[ns]\n",
       "year                                    float64\n",
       "number_of_lanes                         float64\n",
       "speedbin1                               float64\n",
       "speedbin2                               float64\n",
       "speedbin3                               float64\n",
       "speedbin4                               float64\n",
       "speedbin5                               float64\n",
       "speedbin6                               float64\n",
       "speedbin7                               float64\n",
       "speedbin8                               float64\n",
       "speedbin9                               float64\n",
       "summary_interval_minutes                float64\n",
       "vehicle_classification_scheme           float64\n",
       "dir1_id                                 float64\n",
       "dir2_id                                 float64\n",
       "station_name                             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datetimes(df):\n",
    "    if df.loc[df[0] == \"10\"].empty:\n",
    "        duration_min_col = 4\n",
    "        date_col = 2\n",
    "        time_col = 3\n",
    "        add_day = 1\n",
    "        date_col_name = \"end_date\"\n",
    "        time_col_name = \"end_time\"\n",
    "        typ = \"sum\"\n",
    "        max_time_str_len = int(df[time_col].str.len().max())\n",
    "    else:\n",
    "        date_col = 4\n",
    "        time_col = 5\n",
    "        add_day = 0\n",
    "        date_col_name = \"departure_date\"\n",
    "        time_col_name = \"departure_time\"\n",
    "        typ = \"indv\"\n",
    "        max_time_str_len = int(df[time_col].str.len().max())\n",
    "    date_fmt = \"%Y%m%d\"  # YYYYMMDD\n",
    "    date_format = \"%Y-%m-%d\"  # YYYY-MM-DD\n",
    "    time_fmt = \"%H%M%S%f\"  # (includes 00000000, 000000, 0000000)\n",
    "    time_format = \"%H:%M:%S.%f\"  # 00:00:00.00\n",
    "\n",
    "    df[time_col] = df[time_col].str.pad(\n",
    "        width=max_time_str_len, side='right', fillchar=\"0\")\n",
    "    df[time_col].loc[df[time_col].str[:2] == '24'] = (\n",
    "        '0').zfill(max_time_str_len)\n",
    "\n",
    "    df[date_col] = df[date_col].apply(lambda x: str(date.today())[:2]+x if int(x[:2]) <= 50 and len(\n",
    "        x) == 6 else (str(int(str(date.today())[:2])-1)+x if int(x[:2]) > 50 and len(x) == 6 else x))\n",
    "\n",
    "    if typ == \"indv\":\n",
    "        df[date_col] = pd.to_datetime(\n",
    "            df[date_col], format=date_fmt).dt.strftime(date_format)\n",
    "    else:\n",
    "        df[date_col] = df[date_col].apply(lambda x: pd.to_datetime(\n",
    "            x, format=date_fmt).date() + timedelta(days=add_day)\n",
    "            if x[time_col] in ['0'.zfill(max_time_str_len), '24'.ljust(max_time_str_len, '0')]\n",
    "            else pd.to_datetime(x, format=date_fmt).date())\n",
    "\n",
    "    df['end_datetime'] = pd.to_datetime((df[date_col].astype(str)+df[time_col].astype(str)),\n",
    "                                        format=date_format+time_fmt)\n",
    "\n",
    "    if df.loc[df[0] == \"10\"].empty:\n",
    "        df['start_datetime'] = df.apply(lambda x: pd.to_datetime(str(x[date_col])+str(\n",
    "            x[time_col]), format=date_format+time_fmt) - timedelta(minutes=int(x[duration_min_col])), axis=1)\n",
    "    else:\n",
    "        df['start_datetime'] = pd.to_datetime(\n",
    "            df[date_col]+df[time_col], format=date_format+time_fmt)\n",
    "\n",
    "    df[time_col] = pd.to_datetime(\n",
    "        df[time_col], format=time_fmt).dt.strftime(time_format)\n",
    "\n",
    "    df.rename(columns={\n",
    "        date_col: date_col_name,\n",
    "        time_col: time_col_name\n",
    "    }, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_datetimes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lanes(df):\n",
    "    if df.empty:\n",
    "        pass\n",
    "    else:\n",
    "        lanes = df.loc[\n",
    "            df[0] == \"L1\"\n",
    "        ].dropna(axis=1).drop_duplicates().reset_index(drop=True).copy()\n",
    "        if lanes.empty:\n",
    "            lanes = df.loc[\n",
    "            df[0] == \"L0\"\n",
    "            ].dropna(axis=1).drop_duplicates().reset_index(drop=True).copy()\n",
    "            max_lanes = lanes[1].astype(int).at[0]\n",
    "        else:\n",
    "            lanes = lanes.drop([17, 18, 19, 20, 21, 22, 23,\n",
    "                                24, 25], axis=1, errors='ignore')\n",
    "            if lanes.shape[1] == 5:\n",
    "                lanes.rename(columns={\n",
    "                    1: \"lane_number\",\n",
    "                    2: \"direction_code\",\n",
    "                    3: \"lane_type_code\",\n",
    "                    4: \"traffic_stream_number\"\n",
    "                }, inplace=True)\n",
    "            elif lanes.shape[1] == 11:\n",
    "                lanes.rename(columns={\n",
    "                    1: \"lane_number\",\n",
    "                    2: \"direction_code\",\n",
    "                    3: \"lane_type_code\",\n",
    "                    4: \"traffic_stream_number\",\n",
    "                    5: \"traffic_stream_lane_position\",\n",
    "                    6: \"reverse_direction_lane_number\",\n",
    "                    7: \"vehicle_code\",\n",
    "                    8: \"time_code\",\n",
    "                    9: \"length_code\",\n",
    "                    10: \"speed_code\"\n",
    "                }, inplace=True)\n",
    "            elif lanes.shape[1] == 17:\n",
    "                lanes.rename(columns={\n",
    "                    1: \"lane_number\",\n",
    "                    2: \"direction_code\",\n",
    "                    3: \"lane_type_code\",\n",
    "                    4: \"traffic_stream_number\",\n",
    "                    5: \"traffic_stream_lane_position\",\n",
    "                    6: \"reverse_direction_lane_number\",\n",
    "                    7: \"vehicle_code\",\n",
    "                    8: \"time_code\",\n",
    "                    9: \"length_code\",\n",
    "                    10: \"speed_code\",\n",
    "                    11: \"occupancy_time_code\",\n",
    "                    12: \"vehicle_following_code\",\n",
    "                    13: \"trailer_code\",\n",
    "                    14: \"axle_code\",\n",
    "                    15: \"mass_code\",\n",
    "                    16: \"tyre_type_code\"\n",
    "                }, inplace=True)\n",
    "            else:\n",
    "                lanes.rename(columns={\n",
    "                    1: \"lane_number\",\n",
    "                    2: \"direction_code\",\n",
    "                    3: \"lane_type_code\",\n",
    "                    4: \"traffic_stream_number\"\n",
    "                }, inplace=True)\n",
    "            lanes[lanes.select_dtypes(include=['object']).columns] = lanes[\n",
    "                lanes.select_dtypes(include=['object']).columns].apply(\n",
    "                    pd.to_numeric, axis=1, errors='ignore')\n",
    "            lanes[\"site_name\"] = \"site_id\"\n",
    "            try:\n",
    "                max_lanes = int(lanes['lane_number'].astype(int).max())\n",
    "            except ValueError:\n",
    "                max_lanes = int(\n",
    "                    lanes['lane_number'].drop_duplicates().count())\n",
    "        return lanes, max_lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanes, max_lanes = get_lanes(head_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direction(df, lanes, max_lanes):\n",
    "    try:\n",
    "        if df.loc[df[0] == \"10\"].empty:\n",
    "            lane_col = 5\n",
    "        else:\n",
    "            lane_col = 6\n",
    "        \n",
    "        try:\n",
    "            dir_1 = lanes[\"direction_code\"].astype(int).min()\n",
    "            dir_2 = lanes[\"direction_code\"].astype(int).max()\n",
    "        except (TypeError, ValueError):\n",
    "            dir_1 = 0\n",
    "            dir_2 = 4\n",
    "\n",
    "        direction_1 = 'P'\n",
    "        direction_2 = 'N'\n",
    "\n",
    "        if dir_1 == dir_2:\n",
    "            dir_2 = dir_1\n",
    "            direction_2 = direction_1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        df['direction'] = df[lane_col].astype(int)\n",
    "        df['compass_heading'] = df[lane_col].astype(int)\n",
    "        df['direction_code'] = df[lane_col].astype(int)\n",
    "        df['direction'].loc[df[lane_col].astype(int).isin(\n",
    "            list(lanes['lane_number'].astype(\n",
    "                int).loc[lanes['direction_code'].astype(int) == dir_1])\n",
    "        )] = direction_1\n",
    "        df['direction'].loc[df[lane_col].astype(int).isin(\n",
    "            list(lanes['lane_number'].astype(\n",
    "                int).loc[lanes['direction_code'].astype(int) == dir_2])\n",
    "        )] = direction_2\n",
    "        df['compass_heading'].loc[df[lane_col].astype(int).isin(\n",
    "            list(lanes['lane_number'].astype(\n",
    "                int).loc[lanes['direction_code'].astype(int) == dir_1])\n",
    "        )] = str(dir_1)\n",
    "        df['compass_heading'].loc[df[lane_col].astype(int).isin(\n",
    "            list(lanes['lane_number'].astype(\n",
    "                int).loc[lanes['direction_code'].astype(int) == dir_2])\n",
    "        )] = str(dir_2)\n",
    "        df['direction_code'].loc[df[lane_col].astype(int).isin(\n",
    "            list(lanes['lane_number'].astype(\n",
    "                int).loc[lanes['direction_code'].astype(int) == dir_2])\n",
    "        )] = str(dir_2)\n",
    "        df['direction_code'].loc[df[lane_col].astype(int).isin(\n",
    "            list(lanes['lane_number'].astype(\n",
    "                int).loc[lanes['direction_code'].astype(int) == dir_1])\n",
    "        )] = str(dir_1)\n",
    "\n",
    "        return df\n",
    "    except KeyError:\n",
    "        df[lane_col] = df[lane_col].astype(int)\n",
    "        df['direction'] = df.apply(\n",
    "            lambda x: 'P' if int(x[lane_col]) <= int(max_lanes)/2 else 'N', axis=1)\n",
    "        df['direction_code'] = df.apply(\n",
    "            lambda x: 0 if int(x[lane_col]) <= int(max_lanes)/2 else 4, axis=1)\n",
    "        df['compass_heading'] = df.apply(\n",
    "            lambda x: 0 if int(x[lane_col]) <= int(max_lanes)/2 else 4, axis=1)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_direction(df, lanes, max_lanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_time</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>end_datetime</th>\n",
       "      <th>start_datetime</th>\n",
       "      <th>direction</th>\n",
       "      <th>direction_code</th>\n",
       "      <th>compass_heading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>00:03:50.200000</td>\n",
       "      <td>04</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>904</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>00</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>539</td>\n",
       "      <td>35</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-01-01 00:03:50.200</td>\n",
       "      <td>2009-12-31 23:59:50.200</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>00:17:39.970000</td>\n",
       "      <td>04</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>1546</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>00</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>335</td>\n",
       "      <td>72</td>\n",
       "      <td>734</td>\n",
       "      <td>41</td>\n",
       "      <td>129</td>\n",
       "      <td>41</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-01-01 00:17:39.970</td>\n",
       "      <td>2010-01-01 00:13:39.970</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>00:26:13.000000</td>\n",
       "      <td>04</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1991</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>312</td>\n",
       "      <td>32</td>\n",
       "      <td>132</td>\n",
       "      <td>39</td>\n",
       "      <td>497</td>\n",
       "      <td>19</td>\n",
       "      <td>124</td>\n",
       "      <td>30</td>\n",
       "      <td>284</td>\n",
       "      <td>32</td>\n",
       "      <td>435</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-01-01 00:26:13.000</td>\n",
       "      <td>2010-01-01 00:22:13.000</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>01:00:00.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0001</td>\n",
       "      <td>0004</td>\n",
       "      <td>0019</td>\n",
       "      <td>0026</td>\n",
       "      <td>0043</td>\n",
       "      <td>0042</td>\n",
       "      <td>0021</td>\n",
       "      <td>0010</td>\n",
       "      <td>0006</td>\n",
       "      <td>0003</td>\n",
       "      <td>000187</td>\n",
       "      <td>001</td>\n",
       "      <td>000</td>\n",
       "      <td>001</td>\n",
       "      <td>0010</td>\n",
       "      <td>0010</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-01-01 01:00:00.000</td>\n",
       "      <td>2010-01-01 00:00:00.000</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>01:00:00.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0000</td>\n",
       "      <td>0000</td>\n",
       "      <td>0000</td>\n",
       "      <td>0004</td>\n",
       "      <td>0009</td>\n",
       "      <td>0013</td>\n",
       "      <td>0021</td>\n",
       "      <td>0009</td>\n",
       "      <td>0008</td>\n",
       "      <td>0003</td>\n",
       "      <td>000000</td>\n",
       "      <td>000</td>\n",
       "      <td>000</td>\n",
       "      <td>000</td>\n",
       "      <td>0000</td>\n",
       "      <td>0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-01-01 01:00:00.000</td>\n",
       "      <td>2010-01-01 00:00:00.000</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1    end_date         end_time   4  5     6     7     8     9    10  \\\n",
       "0  13  0  2010-01-01  00:03:50.200000  04  4     0   105   904   999     0   \n",
       "1  13  0  2010-01-01  00:17:39.970000  04  4     0    73  1546   999     0   \n",
       "2  13  0  2010-01-01  00:26:13.000000  04  4     0    80  1991   999     0   \n",
       "3  21  0  2010-01-01  01:00:00.000000  60  1  0001  0004  0019  0026  0043   \n",
       "4  21  0  2010-01-01  01:00:00.000000  60  2  0000  0000  0000  0004  0009   \n",
       "\n",
       "     11    12    13    14    15      16   17   18   19    20    21    22  \\\n",
       "0     0     0     0     5    00       2   28  539   35  None  None  None   \n",
       "1     0     0     0     9    00       4   55  335   72   734    41   129   \n",
       "2     0     0     0     0    00       7   49  312   32   132    39   497   \n",
       "3  0042  0021  0010  0006  0003  000187  001  000  001  0010  0010  None   \n",
       "4  0013  0021  0009  0008  0003  000000  000  000  000  0000  0000  None   \n",
       "\n",
       "     23    24    25    26    27    28    29    30    31    32    33    34  \\\n",
       "0  None  None  None  None  None  None  None  None  None  None  None  None   \n",
       "1    41  None  None  None  None  None  None  None  None  None  None  None   \n",
       "2    19   124    30   284    32   435    20  None  None  None  None  None   \n",
       "3  None  None  None  None  None  None  None  None  None  None  None  None   \n",
       "4  None  None  None  None  None  None  None  None  None  None  None  None   \n",
       "\n",
       "     35    36    37    38    39            end_datetime  \\\n",
       "0  None  None  None  None  None 2010-01-01 00:03:50.200   \n",
       "1  None  None  None  None  None 2010-01-01 00:17:39.970   \n",
       "2  None  None  None  None  None 2010-01-01 00:26:13.000   \n",
       "3  None  None  None  None  None 2010-01-01 01:00:00.000   \n",
       "4  None  None  None  None  None 2010-01-01 01:00:00.000   \n",
       "\n",
       "           start_datetime direction  direction_code  compass_heading  \n",
       "0 2009-12-31 23:59:50.200         N               4                4  \n",
       "1 2010-01-01 00:13:39.970         N               4                4  \n",
       "2 2010-01-01 00:22:13.000         N               4                4  \n",
       "3 2010-01-01 00:00:00.000         P               0                0  \n",
       "4 2010-01-01 00:00:00.000         P               0                0  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def type_30(self) -> pd.DataFrame:\n",
    "data_df = df\n",
    "if data_df is None:\n",
    "    pass\n",
    "else:\n",
    "    data = data_df.loc[(data_df[0] == \"30\")].dropna(\n",
    "        axis=1, how=\"all\"\n",
    "    ).reset_index(drop=True).copy()\n",
    "    header = head_df.loc[(head_df[0] == \"30\")].dropna(\n",
    "        axis=1, how=\"all\"\n",
    "    ).reset_index(drop=True).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data.empty:\n",
    "    pass\n",
    "else:\n",
    "    if header.shape[1] > 3:\n",
    "        classification_scheme = header.iloc[0, 3]\n",
    "        number_of_data_records = header.iloc[0, 4]\n",
    "    else:\n",
    "        classification_scheme = header.iloc[0, 2]\n",
    "        number_of_data_records = header.iloc[0, 3]\n",
    "\n",
    "    # vc_df = select_classification_scheme(classification_scheme)\n",
    "\n",
    "    if data[1].isin([\"0\", \"2\", 0, 2]).any():\n",
    "        ddf = data.iloc[:, 1:].dropna(\n",
    "            axis=1, how=\"all\").reset_index(drop=True)\n",
    "\n",
    "        ddf[ddf.select_dtypes(include=['object']).columns] = ddf[\n",
    "            ddf.select_dtypes(include=['object']).columns].apply(\n",
    "            pd.to_numeric, axis=1, errors='ignore')\n",
    "\n",
    "        ddf['vehicle_classification_scheme'] = int(\n",
    "            classification_scheme)\n",
    "\n",
    "        ddf.columns = ddf.columns.astype(str)\n",
    "\n",
    "        df3 = pd.DataFrame(columns=[\n",
    "            'edit_code',\n",
    "            'start_datetime',\n",
    "            'end_date',\n",
    "            'end_time',\n",
    "            'duration_of_summary',\n",
    "            'lane_number',\n",
    "            'number_of_vehicles',\n",
    "            'class_number',\n",
    "            'direction',\n",
    "            'compass_heading'])\n",
    "        for lane_no in range(1, int(max_lanes)+1):\n",
    "            for i in range(6, int(number_of_data_records)+6):\n",
    "                join_to_df3 = ddf.loc[ddf['5'].astype(int) == lane_no, [\n",
    "                    '1', 'start_datetime', 'end_date', 'end_time', '4', '5', str(i), 'direction', 'compass_heading']]\n",
    "                join_to_df3['class_number'] = i-5\n",
    "                join_to_df3.rename(columns={\n",
    "                    '1': \"edit_code\",\n",
    "                    '2': \"end_date\",\n",
    "                    '3': \"end_time\",\n",
    "                    '4': \"duration_of_summary\",\n",
    "                    '5': 'lane_number',\n",
    "                    str(i): 'number_of_vehicles'\n",
    "                }, inplace=True)\n",
    "                # df3 = pd.concat([df3,join_to_df3],keys=['start_datetime','lane_number','number_of_vehicles','class_number'],ignore_index=True, axis=0)\n",
    "                df3 = pd.concat([df3, join_to_df3], keys=[\n",
    "                                'start_datetime', 'lane_number'], ignore_index=True, axis=0)\n",
    "        df3 = df3.apply(pd.to_numeric, axis=1, errors=\"ignore\")\n",
    "        df3['classification_scheme'] = int(classification_scheme)\n",
    "        df3['site_id'] = 'self.site_id'\n",
    "        df3[\"header_id\"] = 'self.header_id'\n",
    "        df3['year'] = int(data['start_datetime'].at[0].year)\n",
    "    else:\n",
    "        pass\n",
    "    # return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[['edit_code','duration_of_summary','lane_number','number_of_vehicles','class_number','compass_heading','classification_scheme','year']] = df3[['edit_code','duration_of_summary','lane_number','number_of_vehicles','class_number','compass_heading','classification_scheme','year']].apply(pd.to_numeric, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edit_code</th>\n",
       "      <th>start_datetime</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_time</th>\n",
       "      <th>duration_of_summary</th>\n",
       "      <th>lane_number</th>\n",
       "      <th>number_of_vehicles</th>\n",
       "      <th>class_number</th>\n",
       "      <th>direction</th>\n",
       "      <th>compass_heading</th>\n",
       "      <th>classification_scheme</th>\n",
       "      <th>site_id</th>\n",
       "      <th>header_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>01:00:00.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>self.site_id</td>\n",
       "      <td>self.header_id</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01 01:00:00</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>02:00:00.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>self.site_id</td>\n",
       "      <td>self.header_id</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01 02:00:00</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>03:00:00.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>self.site_id</td>\n",
       "      <td>self.header_id</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01 03:00:00</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>04:00:00.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>self.site_id</td>\n",
       "      <td>self.header_id</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01 04:00:00</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>05:00:00.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>self.site_id</td>\n",
       "      <td>self.header_id</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  edit_code      start_datetime    end_date         end_time  \\\n",
       "0         0 2010-01-01 00:00:00  2010-01-01  01:00:00.000000   \n",
       "1         0 2010-01-01 01:00:00  2010-01-01  02:00:00.000000   \n",
       "2         0 2010-01-01 02:00:00  2010-01-01  03:00:00.000000   \n",
       "3         0 2010-01-01 03:00:00  2010-01-01  04:00:00.000000   \n",
       "4         0 2010-01-01 04:00:00  2010-01-01  05:00:00.000000   \n",
       "\n",
       "   duration_of_summary  lane_number  number_of_vehicles  class_number  \\\n",
       "0                   60            1                   4             1   \n",
       "1                   60            1                   8             1   \n",
       "2                   60            1                   6             1   \n",
       "3                   60            1                   2             1   \n",
       "4                   60            1                   8             1   \n",
       "\n",
       "  direction  compass_heading  classification_scheme       site_id  \\\n",
       "0         P                0                      8  self.site_id   \n",
       "1         P                0                      8  self.site_id   \n",
       "2         P                0                      8  self.site_id   \n",
       "3         P                0                      8  self.site_id   \n",
       "4         P                0                      8  self.site_id   \n",
       "\n",
       "        header_id  year  \n",
       "0  self.header_id  2010  \n",
       "1  self.header_id  2010  \n",
       "2  self.header_id  2010  \n",
       "3  self.header_id  2010  \n",
       "4  self.header_id  2010  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "t21_data = type_21(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header_calcs(header: pd.DataFrame, data: pd.DataFrame, type: int) -> pd.DataFrame:\n",
    "    try:\n",
    "        speed_limit_qry = f\"select max_speed from trafc.countstation where tcname = '{data['site_id'].iloc[0]}' ;\"\n",
    "        speed_limit = pd.read_sql_query(speed_limit_qry,config.ENGINE).reset_index(drop=True)\n",
    "        try:\n",
    "            speed_limit = speed_limit['max_speed'].iloc[0]\n",
    "        except IndexError:\n",
    "            speed_limit = 60\n",
    "        data = data.fillna(0, axis=0)\n",
    "        if type == 21:\n",
    "            try:\n",
    "                header['adt_total'] = data['total_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('D')]).sum().mean().round().astype(int)\n",
    "                header['adt_positive_direction'] = round(data['total_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('D'), data['direction'].loc[data['direction'] == 'P']]).sum().mean())\n",
    "                header['adt_negative_direction'] = round(data['total_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('D'), data['direction'].loc[data['direction'] == 'N']]).sum().mean())\n",
    "\n",
    "                header['adtt_total'] = data['total_heavy_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('D')]).sum().mean().round().astype(int)\n",
    "                header['adtt_positive_direction'] = round(data['total_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('D'), data['direction'].loc[data['direction'] == 'P']]).sum().mean())\n",
    "                header['adtt_negative_direction'] = round(data['total_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('D'), data['direction'].loc[data['direction'] == 'N']]).sum().mean())\n",
    "\n",
    "                header['total_vehicles'] = data['total_vehicles_type21'].sum()\n",
    "                header['total_vehicles_positive_direction'] = data['total_vehicles_type21'].groupby(data['direction'].loc[data['direction'] == 'P']).sum()[0]\n",
    "                header['total_vehicles_negative_direction'] = data['total_vehicles_type21'].groupby(data['direction'].loc[data['direction'] == 'N']).sum()[0]\n",
    "\n",
    "                header['total_heavy_vehicles'] = data['total_heavy_vehicles_type21'].sum()\n",
    "                header['total_heavy_negative_direction'] = data['total_heavy_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0]\n",
    "                header['total_heavy_positive_direction'] = data['total_heavy_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0]\n",
    "                header['truck_split_negative_direction'] = data['total_heavy_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0] / data['total_heavy_vehicles_type21'].sum()\n",
    "                header['truck_split_positive_direction'] = data['total_heavy_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0] / data['total_heavy_vehicles_type21'].sum()\n",
    "\n",
    "                header['total_light_vehicles'] = data['total_light_vehicles_type21'].sum()\n",
    "                header['total_light_positive_direction'] = data['total_light_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0]\n",
    "                header['total_light_negative_direction'] = data['total_light_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0]\n",
    "\n",
    "                header['short_heavy_vehicles'] = data['short_heavy_vehicles'].sum()\n",
    "                header['short_heavy_positive_direction'] = data['short_heavy_vehicles'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0]\n",
    "                header['short_heavy_negative_direction'] = data['short_heavy_vehicles'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0]\n",
    "\n",
    "                header['Medium_heavy_vehicles'] = data['medium_heavy_vehicles'].sum()\n",
    "                header['Medium_heavy_negative_direction'] = data['medium_heavy_vehicles'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0]\n",
    "                header['Medium_heavy_positive_direction'] = data['medium_heavy_vehicles'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0]\n",
    "\n",
    "                header['long_heavy_vehicles'] = data['long_heavy_vehicles'].sum()\n",
    "                header['long_heavy_positive_direction'] = data['long_heavy_vehicles'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0]\n",
    "                header['long_heavy_negative_direction'] = data['long_heavy_vehicles'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0]\n",
    "\n",
    "                header['vehicles_with_rear_to_rear_headway_less_than_2sec_positive_dire'] = data['rear_to_rear_headway_shorter_than_2_seconds'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0]\n",
    "                header['vehicles_with_rear_to_rear_headway_less_than_2sec_negative_dire'] = data['rear_to_rear_headway_shorter_than_2_seconds'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0]\n",
    "                header['vehicles_with_rear_to_rear_headway_less_than_2sec_total'] = data['rear_to_rear_headway_shorter_than_2_seconds'].sum()\n",
    "            \n",
    "                header['type_21_count_interval_minutes'] = data['duration_min'].mean()\n",
    "\n",
    "                header['highest_volume_per_hour_positive_direction'] = round(data['total_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('H'), data['direction'].loc[data['direction'] == 'P']]).sum().max())\n",
    "                header['highest_volume_per_hour_negative_direction'] = round(data['total_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('H'), data['direction'].loc[data['direction'] == 'N']]).sum().max())\n",
    "                header['highest_volume_per_hour_total'] = data['total_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('H')]).sum().max()\n",
    "\n",
    "                header['15th_highest_volume_per_hour_positive_direction'] = round(data['total_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('H'), data['direction'].loc[data['direction'] == 'P']]).sum().quantile(q=0.15,  interpolation='linear'))\n",
    "                header['15th_highest_volume_per_hour_negative_direction'] = round(data['total_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('H'), data['direction'].loc[data['direction'] == 'N']]).sum().quantile(q=0.15,  interpolation='linear'))\n",
    "                header['15th_highest_volume_per_hour_total'] = round(data['total_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('H')]).sum().quantile(q=0.15, interpolation='linear'))\n",
    "                \n",
    "                header['30th_highest_volume_per_hour_positive_direction'] = round(data['total_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('H'), data['direction'].loc[data['direction'] == 'P']]).sum().quantile(q=0.3,  interpolation='linear'))\n",
    "                header['30th_highest_volume_per_hour_negative_direction'] = round(data['total_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('H'), data['direction'].loc[data['direction'] == 'N']]).sum().quantile(q=0.3, interpolation='linear'))\n",
    "                header['30th_highest_volume_per_hour_total'] = round(data['total_vehicles_type21'].groupby([data['start_datetime'].dt.to_period('H')]).sum().quantile(q=0.3, interpolation='linear'))\n",
    "\n",
    "                # header['average_speed_positive_direction'] = \n",
    "                # header['average_speed_negative_direction'] = \n",
    "                try:\n",
    "                    header['average_speed'] = (int((\n",
    "                    (header['speedbin1'] * data['speedbin1'].sum()) +\n",
    "                    (header['speedbin2'] * data['speedbin2'].sum()) +\n",
    "                    (header['speedbin3'] * data['speedbin3'].sum()) +\n",
    "                    (header['speedbin4'] * data['speedbin4'].sum()) +\n",
    "                    (header['speedbin5'] * data['speedbin5'].sum()) +\n",
    "                    (header['speedbin6'] * data['speedbin6'].sum()) +\n",
    "                    (header['speedbin7'] * data['speedbin7'].sum()) +\n",
    "                    (header['speedbin8'] * data['speedbin8'].sum()) +\n",
    "                    (header['speedbin9'] * data['speedbin9'].sum()) \n",
    "                    ))\n",
    "                    / data['sum_of_heavy_vehicle_speeds'].astype(int).sum()\n",
    "                    )\n",
    "                except TypeError:\n",
    "                    header['average_speed'] = (((\n",
    "                    (header['speedbin1'] * data['speedbin1'].astype(int).sum()) +\n",
    "                    (header['speedbin2'] * data['speedbin2'].astype(int).sum()) +\n",
    "                    (header['speedbin3'] * data['speedbin3'].astype(int).sum()) +\n",
    "                    (header['speedbin4'] * data['speedbin4'].astype(int).sum()) +\n",
    "                    (header['speedbin5'] * data['speedbin5'].astype(int).sum()) +\n",
    "                    (header['speedbin6'] * data['speedbin6'].astype(int).sum()) +\n",
    "                    (header['speedbin7'] * data['speedbin7'].astype(int).sum()) +\n",
    "                    (header['speedbin8'] * data['speedbin8'].astype(int).sum()) +\n",
    "                    (header['speedbin9'] * data['speedbin9'].astype(int).sum()) \n",
    "                    ))\n",
    "                    / data['sum_of_heavy_vehicle_speeds'].astype(int).sum()\n",
    "                    )\n",
    "                # header['average_speed_light_vehicles_positive_direction'] = \n",
    "                # header['average_speed_light_vehicles_negative_direction'] = \n",
    "                header['average_speed_light_vehicles'] = ((\n",
    "                    (header['speedbin1'] * data['speedbin1'].sum()) +\n",
    "                    (header['speedbin2'] * data['speedbin2'].sum()) +\n",
    "                    (header['speedbin3'] * data['speedbin3'].sum()) +\n",
    "                    (header['speedbin4'] * data['speedbin4'].sum()) +\n",
    "                    (header['speedbin5'] * data['speedbin5'].sum()) +\n",
    "                    (header['speedbin6'] * data['speedbin6'].sum()) +\n",
    "                    (header['speedbin7'] * data['speedbin7'].sum()) +\n",
    "                    (header['speedbin8'] * data['speedbin8'].sum()) +\n",
    "                    (header['speedbin9'] * data['speedbin9'].sum()) -\n",
    "                    data['sum_of_heavy_vehicle_speeds'].sum()\n",
    "                    )\n",
    "                    / data['sum_of_heavy_vehicle_speeds'].sum()\n",
    "                    )\n",
    "                \n",
    "                # header['average_speed_heavy_vehicles_positive_direction'] = \n",
    "                # header['average_speed_heavy_vehicles_negative_direction'] = \n",
    "                # header['average_speed_heavy_vehicles'] = \n",
    "                \n",
    "                try:\n",
    "                    header['truck_split_positive_direction'] = (str(\n",
    "                        round(data['short_heavy_vehicles'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0] / \n",
    "                        data['total_heavy_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0]*100)) \n",
    "                    + ' : ' +\n",
    "                    str(\n",
    "                        round(data['medium_heavy_vehicles'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0] / \n",
    "                        data['total_heavy_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0]*100)) \n",
    "                    + ' : ' +\n",
    "                    str(\n",
    "                        round(data['long_heavy_vehicles'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0] / \n",
    "                        data['total_heavy_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0]*100))\n",
    "                    )\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    header['truck_split_negative_direction'] = (str(\n",
    "                        round(data['short_heavy_vehicles'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0] / \n",
    "                        data['total_heavy_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()*100)) \n",
    "                        + ' : ' +\n",
    "                    str(\n",
    "                        round(data['medium_heavy_vehicles'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0] / \n",
    "                        data['total_heavy_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0]*100)) \n",
    "                    + ' : ' +\n",
    "                    str(\n",
    "                        round(data['long_heavy_vehicles'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0] / \n",
    "                        data['total_heavy_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0]*100))\n",
    "                    )\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                try:\n",
    "                    header['truck_split_total'] = (str(\n",
    "                        round(data['short_heavy_vehicles'].sum() / \n",
    "                        data['total_heavy_vehicles_type21'].sum()*100)) \n",
    "                        + ' : ' +\n",
    "                    str(\n",
    "                        round(data['medium_heavy_vehicles'].sum() / \n",
    "                        data['total_heavy_vehicles_type21'].sum()*100)) \n",
    "                    + ' : ' +\n",
    "                    str(\n",
    "                        round(data['long_heavy_vehicles'].sum() / \n",
    "                        data['total_heavy_vehicles_type21'].sum()*100))\n",
    "                    )\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "            except KeyError:\n",
    "                pass\n",
    "            try:\n",
    "                header[\"type_21_count_interval_minutes\"] = header[\"type_21_count_interval_minutes\"].round().astype(int)\n",
    "            except (KeyError, pd.errors.IntCastingNaNError):\n",
    "                pass\n",
    "\n",
    "            return header\n",
    "        \n",
    "        elif type == 30:\n",
    "            try:\n",
    "                if header['adt_total'].isnull().all():\n",
    "                    header['adt_total'] = data['total_vehicles_type30'].groupby([data['start_datetime'].dt.to_period('D')]).sum().mean().astype(int)\n",
    "                    header['adt_positive_direction'] = round(data['total_vehicles_type30'].groupby([data['start_datetime'].dt.to_period('D'), data['direction'].loc[data['direction'] == 'P']]).sum().mean())\n",
    "                    header['adt_negative_direction'] = round(data['total_vehicles_type30'].groupby([data['start_datetime'].dt.to_period('D'), data['direction'].loc[data['direction'] == 'N']]).sum().mean())\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                if header['adtt_total'].isnull().all():\n",
    "                    header['adtt_total'] = data['total_heavy_vehicles_type30'].groupby([data['start_datetime'].dt.to_period('D')]).sum().mean().astype(int)\n",
    "                    header['adtt_positive_direction'] = round(data['total_vehicles_type30'].groupby([data['start_datetime'].dt.to_period('D'), data['direction'].loc[data['direction'] == 'P']]).sum().mean())\n",
    "                    header['adtt_negative_direction'] = round(data['total_vehicles_type30'].groupby([data['start_datetime'].dt.to_period('D'), data['direction'].loc[data['direction'] == 'N']]).sum().mean())\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                if header['total_vehicles'].isnull().all():\n",
    "                    header['total_vehicles'] = data['total_vehicles_type30'].sum()\n",
    "                    header['total_vehicles_positive_direction'] = data['total_vehicles_type30'].groupby(data['direction'].loc[data['direction'] == 'P']).sum()[0]\n",
    "                    header['total_vehicles_negative_direction'] = data['total_vehicles_type30'].groupby(data['direction'].loc[data['direction'] == 'N']).sum()[0]\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "                if header['total_heavy_vehicles'].isnull().all():\n",
    "                    header['total_heavy_vehicles'] = data['total_heavy_vehicles_type21'].sum()\n",
    "                    header['total_heavy_negative_direction'] = data['total_heavy_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0]\n",
    "                    header['total_heavy_positive_direction'] = data['total_heavy_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0]\n",
    "                    header['truck_split_negative_direction'] = data['total_heavy_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0] / data['total_heavy_vehicles_type21'].sum()\n",
    "                    header['truck_split_positive_direction'] = data['total_heavy_vehicles_type21'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0] / data['total_heavy_vehicles_type21'].sum()\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                if header['total_light_vehicles'].isnull().all():\n",
    "                    header['total_light_vehicles'] = data['total_light_vehicles_type30'].sum()\n",
    "                    header['total_light_positive_direction'] = data['total_light_vehicles_type30'].groupby([data['direction'].loc[data['direction'] == 'P']]).sum()[0]\n",
    "                    header['total_light_negative_direction'] = data['total_light_vehicles_type30'].groupby([data['direction'].loc[data['direction'] == 'N']]).sum()[0]\n",
    "                else:\n",
    "                    pass\n",
    "            except KeyError:\n",
    "                pass\n",
    "                \n",
    "            try:\n",
    "                header['type_30_vehicle_classification_scheme'] = header['type_30_vehicle_classification_scheme'].round().astype(int)\n",
    "            except (KeyError, pd.errors.IntCastingNaNError):\n",
    "                pass\n",
    "\n",
    "            return header\n",
    "\n",
    "        elif type == 70:\n",
    "\n",
    "            try:\n",
    "                header['type_70_maximum_gap_milliseconds'] = header['type_70_maximum_gap_milliseconds'].round().astype(int)\n",
    "            except (KeyError, pd.errors.IntCastingNaNError):\n",
    "                pass\n",
    "            \n",
    "            return header\n",
    "        \n",
    "        elif type == 10:\n",
    "            header['total_light_negative_direction'] = data.loc[(data['vehicle_class_code_secondary_scheme']<=1)&(data['direction']=='N')].count()[0].round().astype(int)\n",
    "            header['total_light_positive_direction'] = data.loc[(data['vehicle_class_code_secondary_scheme']<=1)&(data['direction']=='P')].count()[0].round().astype(int)\n",
    "            header['total_light_vehicles'] = data.loc[data['vehicle_class_code_secondary_scheme']<=1].count()[0].round().astype(int)\n",
    "            header['total_heavy_negative_direction'] = data.loc[(data['vehicle_class_code_secondary_scheme']>1)&(data['direction']=='N')].count()[0].round().astype(int)\n",
    "            header['total_heavy_positive_direction'] = data.loc[(data['vehicle_class_code_secondary_scheme']>1)&(data['direction']=='P')].count()[0].round().astype(int)\n",
    "            header['total_heavy_vehicles'] = data.loc[data['vehicle_class_code_secondary_scheme']>1].count()[0].round().astype(int)\n",
    "            header['total_short_heavy_negative_direction'] = data.loc[(data['vehicle_class_code_secondary_scheme']==2)&(data['direction']=='N')].count()[0].round().astype(int)\n",
    "            header['total_short_heavy_positive_direction'] = data.loc[(data['vehicle_class_code_secondary_scheme']==2)&(data['direction']=='P')].count()[0].round().astype(int)\n",
    "            header['total_short_heavy_vehicles'] = data.loc[data['vehicle_class_code_secondary_scheme']==2].count()[0].round().astype(int)\n",
    "            header['total_medium_heavy_negative_direction'] = data.loc[(data['vehicle_class_code_secondary_scheme']==3)&(data['direction']=='N')].count()[0].round().astype(int)\n",
    "            header['total_medium_heavy_positive_direction'] = data.loc[(data['vehicle_class_code_secondary_scheme']==3)&(data['direction']=='P')].count()[0].round().astype(int)\n",
    "            header['total_medium_heavy_vehicles'] = data.loc[data['vehicle_class_code_secondary_scheme']==3].count()[0].round().astype(int)\n",
    "            header['total_long_heavy_negative_direction'] = data.loc[(data['vehicle_class_code_secondary_scheme']==4)&(data['direction']=='N')].count()[0].round().astype(int)\n",
    "            header['total_long_heavy_positive_direction'] = data.loc[(data['vehicle_class_code_secondary_scheme']==4)&(data['direction']=='P')].count()[0].round().astype(int)\n",
    "            header['total_long_heavy_vehicles'] = data.loc[data['vehicle_class_code_secondary_scheme']==4].count()[0].round().astype(int)\n",
    "            header['total_vehicles_negative_direction'] = data.loc[data['direction']=='N'].count()[0].round().astype(int)\n",
    "            header['total_vehicles_positive_direction'] = data.loc[data['direction']=='P'].count()[0].round().astype(int)\n",
    "            header['total_vehicles'] = data.count()[0].round().astype(int)\n",
    "            header['average_speed_negative_direction'] = data.loc[data['direction']=='N']['vehicle_speed'].mean().round(2)\n",
    "            header['average_speed_positive_direction'] = data.loc[data['direction']=='P']['vehicle_speed'].mean().round(2)\n",
    "            header['average_speed'] = data['vehicle_speed'].mean().round(2)\n",
    "            header['average_speed_light_vehicles_negative_direction'] = data['vehicle_speed'].loc[(data['vehicle_class_code_secondary_scheme']<=1)&(data['direction']=='N')].mean().round(2)\n",
    "            header['average_speed_light_vehicles_positive_direction'] = data['vehicle_speed'].loc[(data['vehicle_class_code_secondary_scheme']<=1)&(data['direction']=='P')].mean().round(2)\n",
    "            header['average_speed_light_vehicles'] = data['vehicle_speed'].loc[data['vehicle_class_code_secondary_scheme']<=1].mean().round(2)\n",
    "            header['average_speed_heavy_vehicles_negative_direction'] = data['vehicle_speed'].loc[(data['vehicle_class_code_secondary_scheme']>1)&(data['direction']=='N')].mean().round(2)\n",
    "            header['average_speed_heavy_vehicles_positive_direction'] = data['vehicle_speed'].loc[(data['vehicle_class_code_secondary_scheme']>1)&(data['direction']=='P')].mean().round(2)\n",
    "            header['average_speed_heavy_vehicles'] = data['vehicle_speed'].loc[data['vehicle_class_code_secondary_scheme']>1].mean().round(2)\n",
    "            header['truck_split_negative_direction'] = {str((((data.loc[(data['vehicle_class_code_secondary_scheme']==2)&(data['direction']=='N')].count()/data.loc[(data['vehicle_class_code_secondary_scheme']>1)&(data['direction']=='N')].count())[0])*100).round().astype(int)) +\":\"+ str((((data.loc[(data['vehicle_class_code_secondary_scheme']==3)&(data['direction']=='N')].count()/data.loc[(data['vehicle_class_code_secondary_scheme']>1)&(data['direction']=='N')].count())[0])*100).round().astype(int)) +\":\"+ str((((data.loc[(data['vehicle_class_code_secondary_scheme']==4)&(data['direction']=='N')].count()/data.loc[(data['vehicle_class_code_secondary_scheme']>1)&(data['direction']=='N')].count())[0])*100).round().astype(int))}\n",
    "            header['truck_split_positive_direction'] = {str((((data.loc[(data['vehicle_class_code_secondary_scheme']==2)&(data['direction']=='P')].count()/data.loc[(data['vehicle_class_code_secondary_scheme']>1)&(data['direction']=='P')].count())[0])*100).round().astype(int)) +\":\"+ str((((data.loc[(data['vehicle_class_code_secondary_scheme']==3)&(data['direction']=='P')].count()/data.loc[(data['vehicle_class_code_secondary_scheme']>1)&(data['direction']=='P')].count())[0])*100).round().astype(int)) +\":\"+ str((((data.loc[(data['vehicle_class_code_secondary_scheme']==4)&(data['direction']=='P')].count()/data.loc[(data['vehicle_class_code_secondary_scheme']>1)&(data['direction']=='P')].count())[0])*100).round().astype(int))}\n",
    "            header['truck_split_total'] = {str((((data.loc[data['vehicle_class_code_secondary_scheme']==2].count()/data.loc[data['vehicle_class_code_secondary_scheme']>1].count())[0])*100).round().astype(int)) +\":\"+ str((((data.loc[data['vehicle_class_code_secondary_scheme']==3].count()/data.loc[data['vehicle_class_code_secondary_scheme']>1].count())[0])*100).round().astype(int)) +\":\"+ str((((data.loc[data['vehicle_class_code_secondary_scheme']==4].count()/data.loc[data['vehicle_class_code_secondary_scheme']>1].count())[0])*100).round().astype(int))}\n",
    "            header['estimated_axles_per_truck_negative_direction'] = ((data.loc[(data['vehicle_class_code_secondary_scheme']==2)&(data['direction']=='N')].count()[0]*2+data.loc[(data['vehicle_class_code_secondary_scheme']==3)&(data['direction']=='N')].count()[0]*5+data.loc[(data['vehicle_class_code_secondary_scheme']==4)&(data['direction']=='N')].count()[0]*7)/(data.loc[(data['vehicle_class_code_secondary_scheme']==2)&(data['direction']=='N')].count()[0]+data.loc[(data['vehicle_class_code_secondary_scheme']==3)&(data['direction']=='N')].count()[0]+data.loc[(data['vehicle_class_code_secondary_scheme']==4)&(data['direction']=='N')].count()[0])).round(2)\n",
    "            header['estimated_axles_per_truck_positive_direction'] = ((data.loc[(data['vehicle_class_code_secondary_scheme']==2)&(data['direction']=='P')].count()[0]*2+data.loc[(data['vehicle_class_code_secondary_scheme']==3)&(data['direction']=='P')].count()[0]*5+data.loc[(data['vehicle_class_code_secondary_scheme']==4)&(data['direction']=='P')].count()[0]*7)/(data.loc[(data['vehicle_class_code_secondary_scheme']==2)&(data['direction']=='P')].count()[0]+data.loc[(data['vehicle_class_code_secondary_scheme']==3)&(data['direction']=='P')].count()[0]+data.loc[(data['vehicle_class_code_secondary_scheme']==4)&(data['direction']=='P')].count()[0])).round(2)\n",
    "            header['estimated_axles_per_truck_total'] = ((data.loc[data['vehicle_class_code_secondary_scheme']==2].count()[0]*2+data.loc[data['vehicle_class_code_secondary_scheme']==3].count()[0]*5+data.loc[data['vehicle_class_code_secondary_scheme']==4].count()[0]*7)/(data.loc[data['vehicle_class_code_secondary_scheme']==2].count()[0]+data.loc[data['vehicle_class_code_secondary_scheme']==3].count()[0]+data.loc[data['vehicle_class_code_secondary_scheme']==4].count()[0])).round(2)\n",
    "            header['percentage_speeding_positive_direction'] = ((data.loc[(data['vehicle_speed']>speed_limit)&(data['direction']=='P')].count()[0]/data.loc[data['direction'=='P']].count()[0])*100).round(2)\n",
    "            header['percentage_speeding_negative_direction'] = ((data.loc[(data['vehicle_speed']>speed_limit)&(data['direction']=='N')].count()[0]/data.loc[data['direction'=='N']].count()[0])*100).round(2)\n",
    "            header['percentage_speeding_total'] = ((data.loc[data['vehicle_speed']>speed_limit].count()[0]/data.count()[0])*100).round(2)\n",
    "            header['vehicles_with_rear_to_rear_headway_less_than_2sec_negative_dire'] = data.loc[(data['vehicle_following_code']==2)&data['direction']=='N'].count()[0]\n",
    "            header['vehicles_with_rear_to_rear_headway_less_than_2sec_positive_dire'] = data.loc[(data['vehicle_following_code']==2)&data['direction']=='P'].count()[0]\n",
    "            header['vehicles_with_rear_to_rear_headway_less_than_2sec_total'] = data.loc[data['vehicle_following_code']==2].count()[0]\n",
    "            header['estimated_e80_negative_direction'] = data.loc[(data['vehicle_class_code_secondary_scheme']==2)&(data['direction']=='N')].count()[0]*0.6+data.loc[(data['vehicle_class_code_secondary_scheme']==3)&(data['direction']=='N')].count()[0]*2.5+data.loc[(data['vehicle_class_code_secondary_scheme']==4)&(data['direction']=='N')].count()[0]*2.1\n",
    "            header['estimated_e80_positive_direction'] = data.loc[(data['vehicle_class_code_secondary_scheme']==2)&(data['direction']=='P')].count()[0]*0.6+data.loc[(data['vehicle_class_code_secondary_scheme']==3)&(data['direction']=='P')].count()[0]*2.5+data.loc[(data['vehicle_class_code_secondary_scheme']==4)&(data['direction']=='P')].count()[0]*2.1\n",
    "            header['estimated_e80_on_road'] = data.loc[data['vehicle_class_code_secondary_scheme']==2].count()[0]*0.6+data.loc[data['vehicle_class_code_secondary_scheme']==3].count()[0]*2.5+data.loc[data['vehicle_class_code_secondary_scheme']==4].count()[0]*2.1\n",
    "            header['adt_negative_direction'] = data.loc[data['direction']=='N'].groupby(pd.Grouper(key='start_datetime',freq='D')).count().mean()[0].round().astype(int)\n",
    "            header['adt_positive_direction'] = data.loc[data['direction']=='P'].groupby(pd.Grouper(key='start_datetime',freq='D')).count().mean()[0].round().astype(int)\n",
    "            header['adt_total'] = data.groupby(pd.Grouper(key='start_datetime',freq='D')).count().mean()[0].round().astype(int)\n",
    "            header['adtt_negative_direction'] = data.loc[(data['vehicle_class_code_secondary_scheme']>1)&(data['direction']=='N')].groupby(pd.Grouper(key='start_datetime',freq='D')).count().mean()[0].round().astype(int)\n",
    "            header['adtt_positive_direction'] = data.loc[(data['vehicle_class_code_secondary_scheme']>1)&(data['direction']=='P')].groupby(pd.Grouper(key='start_datetime',freq='D')).count().mean()[0].round().astype(int)\n",
    "            header['adtt_total'] = data.loc[data['vehicle_class_code_secondary_scheme']>1].groupby(pd.Grouper(key='start_datetime',freq='D')).count().mean()[0].round().astype(int)\n",
    "            header['highest_volume_per_hour_negative_direction'] = data.loc[data['direction']=='N'].groupby(pd.Grouper(key='start_datetime',freq='H')).count().max()[0]\n",
    "            header['highest_volume_per_hour_positive_direction'] = data.loc[data['direction']=='P'].groupby(pd.Grouper(key='start_datetime',freq='H')).count().max()[0]\n",
    "            header['highest_volume_per_hour_total'] = data.groupby(pd.Grouper(key='start_datetime',freq='H')).count().max()[0]\n",
    "            header[\"15th_highest_volume_per_hour_negative_direction\"] = round(data.loc[data['direction']=='N'].groupby(pd.Grouper(key='start_datetime',freq='D')).count().quantile(0.15)[0].round().astype(int))\n",
    "            header[\"15th_highest_volume_per_hour_positive_direction\"] = round(data.loc[data['direction']=='P'].groupby(pd.Grouper(key='start_datetime',freq='D')).count().quantile(0.15)[0].round().astype(int))\n",
    "            header[\"15th_highest_volume_per_hour_total\"] = data.groupby(pd.Grouper(key='start_datetime',freq='D')).count().quantile(0.15)[0].round().astype(int)\n",
    "            header[\"30th_highest_volume_per_hour_negative_direction\"] = round(data.loc[data['direction']=='N'].groupby(pd.Grouper(key='start_datetime',freq='D')).count().quantile(0.30)[0].round().astype(int))\n",
    "            header[\"30th_highest_volume_per_hour_positive_direction\"] = round(data.loc[data['direction']=='P'].groupby(pd.Grouper(key='start_datetime',freq='D')).count().quantile(0.30)[0].round().astype(int))\n",
    "            header[\"30th_highest_volume_per_hour_total\"] = data.groupby(pd.Grouper(key='start_datetime',freq='D')).count().quantile(0.30)[0].round().astype(int)\n",
    "            header[\"15th_percentile_speed_negative_direction\"] = data.loc[data['direction']=='N']['vehicle_speed'].quantile(0.15).round(2)\n",
    "            header[\"15th_percentile_speed_positive_direction\"] = data.loc[data['direction']=='P']['vehicle_speed'].quantile(0.15).round(2)\n",
    "            header[\"15th_percentile_speed_total\"] = data['vehicle_speed'].quantile(0.15).round(2)\n",
    "            header[\"85th_percentile_speed_negative_direction\"] = data.loc[data['direction']=='N']['vehicle_speed'].quantile(0.85).round(2)\n",
    "            header[\"85th_percentile_speed_positive_direction\"] = data.loc[data['direction']=='P']['vehicle_speed'].quantile(0.85).round(2)\n",
    "            header[\"85th_percentile_speed_total\"] = data['vehicle_speed'].quantile(0.85).round(2)\n",
    "            header['avg_weekday_traffic'] = data.groupby(pd.Grouper(key='start_datetime',freq='B')).count().mean()[0].round().astype(int)\n",
    "            header['number_of_days_counted'] = data.groupby([data['start_datetime'].dt.to_period('D')]).count().count()[0]\n",
    "            header['duration_hours'] = data.groupby([data['start_datetime'].dt.to_period('H')]).count().count()[0]\n",
    "\n",
    "            return header\n",
    "\n",
    "        elif type == 60:\n",
    "            \n",
    "            return header\n",
    "        else:\n",
    "            return header\n",
    "    except IndexError:\n",
    "        return header\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MB2705851\\OneDrive - Surbana Jurong Private Limited\\1_Coding\\GitHub\\brandtosaurus\\traffic_electronic_count_ETL\\test.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/test.ipynb#ch0000015?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m df \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/test.ipynb#ch0000015?line=1'>2</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/test.ipynb#ch0000015?line=2'>3</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/test.ipynb#ch0000015?line=3'>4</a>\u001b[0m     \u001b[39m# data = self.data_df\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "if df is None:\n",
    "    pass\n",
    "else:\n",
    "    # data = self.data_df\n",
    "    data = df.loc[(df[0] == \"10\")].dropna(\n",
    "        axis=1, how=\"all\"\n",
    "    ).reset_index(drop=True).copy()\n",
    "\n",
    "    num_of_fields = int(data.iloc[:,1].unique()[0])\n",
    "    ddf = data.iloc[:,: 2 + num_of_fields]\n",
    "\n",
    "\n",
    "    ddf.rename(columns=config.RENAME_TYPE10_DATA_COLUMNS, inplace=True, errors='ignore')\n",
    "\n",
    "    ddf[\"data_id\"] = ddf.apply(lambda x: uuid.uuid4(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_type_code</th>\n",
       "      <th>number_of_fields_associated_with_the_basic_vehicle_data</th>\n",
       "      <th>data_source_code</th>\n",
       "      <th>edit_code</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>assigned_lane_number</th>\n",
       "      <th>physical_lane_number</th>\n",
       "      <th>forward_reverse_code</th>\n",
       "      <th>vehicle_category</th>\n",
       "      <th>vehicle_class_code_primary_scheme</th>\n",
       "      <th>vehicle_class_code_secondary_scheme</th>\n",
       "      <th>vehicle_speed</th>\n",
       "      <th>vehicle_length</th>\n",
       "      <th>site_occupancy_time_in_milliseconds</th>\n",
       "      <th>chassis_height_code</th>\n",
       "      <th>vehicle_following_code</th>\n",
       "      <th>data_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>15:15:00.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>590</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>d6d2383b-b26e-4118-9acf-16c7e747d510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>15:15:00.800000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>530</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>419b8fdf-e5a1-4b98-8019-f5627cb35d97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>15:15:01.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>500</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>01e9545d-d745-4aa9-95a8-b2f2e03b41a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>15:15:01.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>460</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>fcade08d-c1cb-4b71-98dd-58710d447a2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>15:15:02.200000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>490</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>91a244ff-0eec-4062-a06a-927055f0b5e3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_type_code number_of_fields_associated_with_the_basic_vehicle_data  \\\n",
       "0             10                                                 15        \n",
       "1             10                                                 15        \n",
       "2             10                                                 15        \n",
       "3             10                                                 18        \n",
       "4             10                                                 18        \n",
       "\n",
       "  data_source_code edit_code departure_date   departure_time  \\\n",
       "0                1         0     2022-02-10  15:15:00.000000   \n",
       "1                1         0     2022-02-10  15:15:00.800000   \n",
       "2                1         0     2022-02-10  15:15:01.500000   \n",
       "3                1         0     2022-02-10  15:15:01.700000   \n",
       "4                1         0     2022-02-10  15:15:02.200000   \n",
       "\n",
       "  assigned_lane_number physical_lane_number forward_reverse_code  \\\n",
       "0                    2                    2                    1   \n",
       "1                    3                    3                    1   \n",
       "2                    2                    2                    1   \n",
       "3                    1                    1                    1   \n",
       "4                    4                    4                    1   \n",
       "\n",
       "  vehicle_category vehicle_class_code_primary_scheme  \\\n",
       "0               12                                 2   \n",
       "1               12                                 2   \n",
       "2               12                                 2   \n",
       "3               12                                 2   \n",
       "4               12                                 2   \n",
       "\n",
       "  vehicle_class_code_secondary_scheme vehicle_speed vehicle_length  \\\n",
       "0                                   1           116            590   \n",
       "1                                   1           100            530   \n",
       "2                                   1           107            500   \n",
       "3                                   1            69            460   \n",
       "4                                   1           105            490   \n",
       "\n",
       "  site_occupancy_time_in_milliseconds chassis_height_code  \\\n",
       "0                                                       3   \n",
       "1                                                       1   \n",
       "2                                                       3   \n",
       "3                                                       3   \n",
       "4                                                       3   \n",
       "\n",
       "  vehicle_following_code                               data_id  \n",
       "0                      1  d6d2383b-b26e-4118-9acf-16c7e747d510  \n",
       "1                      2  419b8fdf-e5a1-4b98-8019-f5627cb35d97  \n",
       "2                      2  01e9545d-d745-4aa9-95a8-b2f2e03b41a4  \n",
       "3                      2  fcade08d-c1cb-4b71-98dd-58710d447a2e  \n",
       "4                      2  91a244ff-0eec-4062-a06a-927055f0b5e3  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(head_df.loc[head_df[0]==\"10\", 1].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "5\n",
      "6\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "5\n",
      "6\n",
      "0\n",
      "0\n",
      "3\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "if data.shape[1] > ddf.shape[1]:\n",
    "    sub_data_df = pd.DataFrame(columns=['sub_data_type_code','offset_sensor_detection_code','mass_measurement_resolution_kg', 'number','value'])\n",
    "    for index, row in data.iterrows():\n",
    "        col = int(row[1]) + 2\n",
    "        while col < len(row) - 5 and row[col] != None:\n",
    "            sub_data_type = row[col]\n",
    "            col += 1\n",
    "            no_of_type = int(row[col])\n",
    "            col += 1\n",
    "            if sub_data_type[0].lower() in ['w','a','g']:\n",
    "                odc = row[col]\n",
    "                col += 1\n",
    "                mmr = row[col]\n",
    "                col +=1\n",
    "                for i in range(0,no_of_type):\n",
    "                    tempdf = pd.DataFrame([[\n",
    "                    sub_data_type,\n",
    "                    odc,\n",
    "                    mmr,\n",
    "                    i + 1,\n",
    "                    row[col]]\n",
    "                    ], columns = [\n",
    "                    'sub_data_type_code',\n",
    "                    'offset_sensor_detection_code',\n",
    "                    'mass_measurement_resolution_kg',\n",
    "                    'number',\n",
    "                    'value'\n",
    "                    ])\n",
    "                    sub_data_df = pd.concat([sub_data_df, tempdf])\n",
    "                    col += 1\n",
    "            elif sub_data_type[0].lower() in ['s','t','c']:\n",
    "                for i in range(0,no_of_type):\n",
    "                    tempdf = pd.DataFrame([[ \n",
    "                    sub_data_type,\n",
    "                    i + 1,\n",
    "                    row[col]]], columns = [\n",
    "                    'sub_data_type_code',\n",
    "                    'number',\n",
    "                    'value'])\n",
    "                    sub_data_df = pd.concat([sub_data_df, tempdf])\n",
    "                    col += 1\n",
    "            elif sub_data_type[0].lower() in ['v']:\n",
    "                odc = row[col]\n",
    "                col += 1\n",
    "                for i in range(0,no_of_type):\n",
    "                    tempdf = pd.DataFrame([[\n",
    "                    sub_data_type,\n",
    "                    odc,\n",
    "                    i + 1,\n",
    "                    row[col]]\n",
    "                    ], columns = [\n",
    "                    'sub_data_type_code',\n",
    "                    'offset_sensor_detection_code',\n",
    "                    'number',\n",
    "                    'value'\n",
    "                    ])\n",
    "                    sub_data_df = pd.concat([sub_data_df, tempdf])\n",
    "                    col += 1\n",
    "else:\n",
    "    sub_data_df = pd.DataFrame(columns=['index','sub_data_type_code','offset_sensor_detection_code','mass_measurement_resolution_kg', 'number','value'])\n",
    "\n",
    "    sub_data_df = sub_data_df.merge(ddf['data_id'], how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    ddf = ddf.fillna(0)\n",
    "    ddf[\"assigned_lane_number\"] = ddf[\"assigned_lane_number\"].astype(int)\n",
    "    ddf[\"lane_number\"] = ddf[\"physical_lane_number\"].astype(int)\n",
    "    ddf[\"physical_lane_number\"] = ddf[\"physical_lane_number\"].astype(int)\n",
    "\n",
    "    ddf = ddf.replace(r'^\\s*$', np.NaN, regex=True)\n",
    "    sub_data_df = sub_data_df.replace(r'^\\s*$', np.NaN, regex=True)\n",
    "    sub_data_df = sub_data_df.drop(\"index\", axis=1)\n",
    "\n",
    "    scols = ddf.select_dtypes('object').columns\n",
    "    ddf[scols] = ddf[scols].apply(pd.to_numeric, axis=1, errors='ignore')\n",
    "\n",
    "    ddf['year'] = ddf['start_datetime'].dt.year\n",
    "    ddf[\"site_id\"] = \"site_id\"\n",
    "    ddf[\"header_id\"] = 'header_id'\n",
    "\n",
    "    ddf = ddf[ddf.columns.intersection(t10_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub_data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MB2705851\\OneDrive - Surbana Jurong Private Limited\\1_Coding\\GitHub\\brandtosaurus\\traffic_electronic_count_ETL\\test.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MB2705851/OneDrive%20-%20Surbana%20Jurong%20Private%20Limited/1_Coding/GitHub/brandtosaurus/traffic_electronic_count_ETL/test.ipynb#ch0000019?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(sub_data_df\u001b[39m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sub_data_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(sub_data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_type_code</th>\n",
       "      <th>number_of_fields_associated_with_the_basic_vehicle_data</th>\n",
       "      <th>data_source_code</th>\n",
       "      <th>edit_code</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>assigned_lane_number</th>\n",
       "      <th>physical_lane_number</th>\n",
       "      <th>forward_reverse_code</th>\n",
       "      <th>vehicle_category</th>\n",
       "      <th>vehicle_class_code_primary_scheme</th>\n",
       "      <th>vehicle_class_code_secondary_scheme</th>\n",
       "      <th>vehicle_speed</th>\n",
       "      <th>vehicle_length</th>\n",
       "      <th>site_occupancy_time_in_milliseconds</th>\n",
       "      <th>chassis_height_code</th>\n",
       "      <th>vehicle_following_code</th>\n",
       "      <th>data_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>211201</td>\n",
       "      <td>0000006</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>437</td>\n",
       "      <td>233</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>503cf23c-4845-45a5-b7c8-5391279c579b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>211201</td>\n",
       "      <td>0000128</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>406</td>\n",
       "      <td>215</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>632da10d-9136-4b37-bbe9-e4e4ff66e0cb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>211201</td>\n",
       "      <td>0000221</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>546</td>\n",
       "      <td>296</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6cf05322-f1b3-4cb0-b5f0-cabb5d07bd6b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>211201</td>\n",
       "      <td>0000291</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>442</td>\n",
       "      <td>278</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ae0a03bc-5ad2-473b-83b4-ca5f7bd01b02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>211201</td>\n",
       "      <td>0000472</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>456</td>\n",
       "      <td>271</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2147ad39-6bb5-4321-918a-89152faee3f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>211201</td>\n",
       "      <td>0450384</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>453</td>\n",
       "      <td>328</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19605f8c-efb0-4802-9198-6b4dfa84cd53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>211201</td>\n",
       "      <td>0451329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>483</td>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5ff2a85d-15e3-4af9-8069-02d739142a80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>211201</td>\n",
       "      <td>0451580</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>371</td>\n",
       "      <td>206</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12566212-5cbf-4d72-9353-607f4ba8376e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>211201</td>\n",
       "      <td>0452027</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>451</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>149c516f-1fb0-44c1-91b6-b3f6e31c1da6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>211201</td>\n",
       "      <td>0452077</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>418</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>b27ed6a5-ffe3-412f-b54b-28909f79d7a9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>487 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    data_type_code number_of_fields_associated_with_the_basic_vehicle_data  \\\n",
       "0               10                                                 15        \n",
       "1               10                                                 15        \n",
       "2               10                                                 15        \n",
       "3               10                                                 15        \n",
       "4               10                                                 15        \n",
       "..             ...                                                ...        \n",
       "482             10                                                 15        \n",
       "483             10                                                 15        \n",
       "484             10                                                 15        \n",
       "485             10                                                 15        \n",
       "486             10                                                 15        \n",
       "\n",
       "    data_source_code edit_code departure_date departure_time  \\\n",
       "0                  1         0         211201        0000006   \n",
       "1                  1         0         211201        0000128   \n",
       "2                  1         0         211201        0000221   \n",
       "3                  1         0         211201        0000291   \n",
       "4                  1         0         211201        0000472   \n",
       "..               ...       ...            ...            ...   \n",
       "482                1         0         211201        0450384   \n",
       "483                1         0         211201        0451329   \n",
       "484                1         0         211201        0451580   \n",
       "485                1         0         211201        0452027   \n",
       "486                1         0         211201        0452077   \n",
       "\n",
       "    assigned_lane_number physical_lane_number forward_reverse_code  \\\n",
       "0                      3                    3                    1   \n",
       "1                      2                    2                    1   \n",
       "2                      4                    4                    1   \n",
       "3                      1                    1                    1   \n",
       "4                      2                    2                    1   \n",
       "..                   ...                  ...                  ...   \n",
       "482                    1                    1                    1   \n",
       "483                    1                    1                    1   \n",
       "484                    4                    4                    1   \n",
       "485                    4                    4                    1   \n",
       "486                    4                    4                    1   \n",
       "\n",
       "    vehicle_category vehicle_class_code_primary_scheme  \\\n",
       "0                 10                                 1   \n",
       "1                 10                                 1   \n",
       "2                 10                                 1   \n",
       "3                 10                                 1   \n",
       "4                 10                                 1   \n",
       "..               ...                               ...   \n",
       "482               10                                 1   \n",
       "483               10                                 1   \n",
       "484               10                                 1   \n",
       "485               10                                 1   \n",
       "486               10                                 1   \n",
       "\n",
       "    vehicle_class_code_secondary_scheme vehicle_speed vehicle_length  \\\n",
       "0                                     1            82            437   \n",
       "1                                     1            85            406   \n",
       "2                                     1            72            546   \n",
       "3                                     1            69            442   \n",
       "4                                     1            73            456   \n",
       "..                                  ...           ...            ...   \n",
       "482                                   1            55            453   \n",
       "483                                   1            90            483   \n",
       "484                                   1            82            371   \n",
       "485                                   1            90            451   \n",
       "486                                   1            90            418   \n",
       "\n",
       "    site_occupancy_time_in_milliseconds chassis_height_code  \\\n",
       "0                                   233                   3   \n",
       "1                                   215                   3   \n",
       "2                                   296                   1   \n",
       "3                                   278                   2   \n",
       "4                                   271                   3   \n",
       "..                                  ...                 ...   \n",
       "482                                 328                   1   \n",
       "483                                 235                   3   \n",
       "484                                 206                   3   \n",
       "485                                 220                   3   \n",
       "486                                 208                   3   \n",
       "\n",
       "    vehicle_following_code                               data_id  \n",
       "0                        1  503cf23c-4845-45a5-b7c8-5391279c579b  \n",
       "1                        1  632da10d-9136-4b37-bbe9-e4e4ff66e0cb  \n",
       "2                        1  6cf05322-f1b3-4cb0-b5f0-cabb5d07bd6b  \n",
       "3                        1  ae0a03bc-5ad2-473b-83b4-ca5f7bd01b02  \n",
       "4                        1  2147ad39-6bb5-4321-918a-89152faee3f4  \n",
       "..                     ...                                   ...  \n",
       "482                      1  19605f8c-efb0-4802-9198-6b4dfa84cd53  \n",
       "483                      1  5ff2a85d-15e3-4af9-8069-02d739142a80  \n",
       "484                      1  12566212-5cbf-4d72-9353-607f4ba8376e  \n",
       "485                      1  149c516f-1fb0-44c1-91b6-b3f6e31c1da6  \n",
       "486                      1  b27ed6a5-ffe3-412f-b54b-28909f79d7a9  \n",
       "\n",
       "[487 rows x 18 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f0240ba5a37eeffe7d380595dcf16248afe1beab2227011f0d1b1f050a1a57d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
